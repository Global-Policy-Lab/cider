{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import string\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "synthetic_data_folder = Path(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OBJECTID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m num_towers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      5\u001b[0m shapefile \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(synthetic_data_folder \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregions.geojson\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m shapefile \u001b[38;5;241m=\u001b[39m \u001b[43mshapefile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdissolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOBJECTID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m polygon \u001b[38;5;241m=\u001b[39m shapefile[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m minx, miny, maxx, maxy \u001b[38;5;241m=\u001b[39m polygon\u001b[38;5;241m.\u001b[39mbounds\n",
      "File \u001b[0;32m~/miniconda3/envs/cider/lib/python3.8/site-packages/geopandas/geodataframe.py:1493\u001b[0m, in \u001b[0;36mGeoDataFrame.dissolve\u001b[0;34m(self, by, aggfunc, as_index, level, sort, observed, dropna)\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;66;03m# Process non-spatial component\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mname, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1493\u001b[0m aggregated_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgroupby_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39magg(aggfunc)\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;66;03m# Process spatial component\u001b[39;00m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_geometries\u001b[39m(block):\n",
      "File \u001b[0;32m~/miniconda3/envs/cider/lib/python3.8/site-packages/pandas/core/frame.py:8402\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   8399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   8400\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8405\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8408\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8410\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8413\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cider/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:965\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 965\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/miniconda3/envs/cider/lib/python3.8/site-packages/pandas/core/groupby/grouper.py:888\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    886\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    891\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OBJECTID'"
     ]
    }
   ],
   "source": [
    "# Generate table of towers (out of date, don't run this)\n",
    "if False:\n",
    "    np.random.seed(100)\n",
    "    num_towers = 100\n",
    "\n",
    "    shapefile = gpd.read_file(synthetic_data_folder / 'regions.geojson')\n",
    "    shapefile = shapefile.dissolve(by='OBJECTID')\n",
    "    polygon = shapefile['geometry'][0]\n",
    "\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    lats, lons = [], []\n",
    "    while len(lats) < num_towers:\n",
    "        point = Point(np.random.uniform(minx, maxx), np.random.uniform(miny, maxy))\n",
    "        if polygon.contains(point):\n",
    "            lats.append(point.y)\n",
    "            lons.append(point.x)\n",
    "    points = pd.DataFrame([lats, lons]).T\n",
    "    points.columns = ['latitude', 'longitude']\n",
    "    points['tower_id'] = range(len(points))\n",
    "    points['tower_id'] = points['tower_id'].apply(lambda x: 't' + str(x))\n",
    "    points.to_csv(synthetic_data_folder / 'towers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate table of antennas (out of date, don't run this)\n",
    "if False:\n",
    "    np.random.seed(200)\n",
    "    num_extra_antennas = 10\n",
    "\n",
    "    antennas = []\n",
    "    towers = pd.read_csv(synthetic_data_folder / 'towers.csv')\n",
    "    towerids = towers['tower_id'].values\n",
    "    for towerid in towerids:\n",
    "        num_antennas = np.random.randint(1, 6)\n",
    "        for i in range(num_antennas):\n",
    "            antennas.append(towerid)\n",
    "    antennas = pd.DataFrame(antennas)\n",
    "    antennas.columns = ['tower_id']\n",
    "    antennas['antenna_id'] = range(len(antennas))\n",
    "    antennas['antenna_id'] = antennas['antenna_id'].apply(lambda x: 'a' + str(x))\n",
    "    antennas = antennas[['antenna_id', 'tower_id']]\n",
    "    max_antenna = int(antennas['antenna_id'].values[-1][1:])\n",
    "    antennas_notower = ['a' + str(i) for i in range(max_antenna+1, max_antenna+1+num_extra_antennas)]\n",
    "    antennas_notower = pd.DataFrame([antennas_notower, [np.nan for _ in antennas_notower]]).T\n",
    "    antennas_notower.columns = ['antenna_id', 'tower_id']\n",
    "    antennas = pd.concat([antennas, antennas_notower])\n",
    "    antennas.to_csv(synthetic_data_folder / 'antennas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is generated based on a simplified version of Bangladesh's [mobile phone number format](https://en.wikipedia.org/wiki/Telephone_numbers_in_Bangladesh). We're assuming the following relatively-simple format options, with nothing else permitted:\n",
    "\n",
    "- From within Bangladesh: 0 <3-digit operator prefix> \\<subscriber number>\n",
    "- From outside Bangladesh: +880 <3-digit operator prefix> \\<subscriber number>\n",
    "\n",
    "And where the operator prefix must start with the string '01'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate table of subscribers\n",
    "num_subscribers = 1000\n",
    "random.seed(300)\n",
    "subscriber_number_length = 7\n",
    "max_numeric_value = 10**(subscriber_number_length)\n",
    "\n",
    "subs = []\n",
    "for i in range(num_subscribers):\n",
    "    subscriber_number = str(random.randrange(max_numeric_value)).zfill(subscriber_number_length)\n",
    "    if random.randrange(5) == 0:\n",
    "        subs.append('+880018' + subscriber_number)\n",
    "    else:\n",
    "        subs.append('0018' + subscriber_number)\n",
    "subs = pd.DataFrame(subs)\n",
    "subs.columns = ['subscriber_id']\n",
    "subs.to_csv(synthetic_data_folder / 'subscribers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block generates already-anonymized phone numbers, don't run it\n",
    "if False:\n",
    "    # Generate table of subscribers\n",
    "    num_subscribers = 1000\n",
    "    strlen = 10\n",
    "    random.seed(300)\n",
    "\n",
    "    subs = []\n",
    "    for i in range(num_subscribers):\n",
    "        subs.append(''.join(random.choice(string.ascii_lowercase + string.ascii_uppercase) for _ in range(strlen)))\n",
    "    subs = pd.DataFrame(subs)\n",
    "    subs.columns = ['subscriber_id']\n",
    "    subs.to_csv(synthetic_data_folder / 'subscribers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate call/SMS table\n",
    "np.random.seed(400)\n",
    "num_txns = 100000\n",
    "\n",
    "subs = pd.read_csv(synthetic_data_folder / 'subscribers.csv', dtype={'subscriber_id': str})['subscriber_id'].values.flatten()\n",
    "antenna_dict = pd.read_csv(synthetic_data_folder / 'antennas.csv')\n",
    "antennas = antenna_dict['antenna_id'].values.flatten()\n",
    "towers = pd.read_csv(synthetic_data_folder / 'towers.csv')\n",
    "\n",
    "start = pd.to_datetime('2020-01-01 00:00:00')\n",
    "end = pd.to_datetime('2020-03-01 00:00:00')\n",
    "seconds = ((end - start).days)*24*60*60\n",
    "\n",
    "txns = []\n",
    "while len(txns) < num_txns:\n",
    "    caller = np.random.choice(subs)\n",
    "    recipient = np.random.choice(subs)\n",
    "    caller_antenna = np.random.choice(antennas)\n",
    "    recipient_antenna = np.random.choice(antennas)\n",
    "    international = np.random.choice(['domestic', 'international', 'other'], p=[.98, .01, .01])\n",
    "    if np.random.randint(0, 10) == 0:\n",
    "        caller_antenna = np.nan\n",
    "    if np.random.randint(0, 10) == 0:\n",
    "        recipient_antenna = np.nan\n",
    "    timedif = np.random.randint(0, seconds)\n",
    "    timestamp = start + pd.Timedelta(seconds=timedif)\n",
    "    if caller != recipient:\n",
    "        txns.append([caller, recipient, caller_antenna, recipient_antenna, timestamp, international])\n",
    "\n",
    "txns = pd.DataFrame(txns)\n",
    "txns.columns = ['caller_id', 'recipient_id', 'caller_antenna', 'recipient_antenna', 'timestamp', 'international']\n",
    "txns['txn_type'] = np.random.choice(['call', 'text'], size=len(txns))\n",
    "txns['duration'] = np.random.randint(0, 300, size=len(txns))\n",
    "txns['duration'] = txns.apply(lambda row: row['duration'] if row['txn_type'] == 'call' else np.nan, axis=1)\n",
    "txns = txns.sort_values('timestamp', ascending=True)\n",
    "txns = txns[['txn_type', 'caller_id', 'recipient_id', 'timestamp', 'duration', 'caller_antenna', \n",
    "             'recipient_antenna', 'international']]\n",
    "\n",
    "txns.to_csv(synthetic_data_folder / 'cdr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn_type</th>\n",
       "      <th>caller_id</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>caller_antenna</th>\n",
       "      <th>recipient_antenna</th>\n",
       "      <th>international</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76053</th>\n",
       "      <td>call</td>\n",
       "      <td>00180479117</td>\n",
       "      <td>00186879451</td>\n",
       "      <td>2020-01-01 00:00:42</td>\n",
       "      <td>253.0</td>\n",
       "      <td>a101</td>\n",
       "      <td>a54</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55660</th>\n",
       "      <td>text</td>\n",
       "      <td>00181616517</td>\n",
       "      <td>00185633871</td>\n",
       "      <td>2020-01-01 00:02:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a44</td>\n",
       "      <td>a110</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49363</th>\n",
       "      <td>text</td>\n",
       "      <td>00189653293</td>\n",
       "      <td>00186624501</td>\n",
       "      <td>2020-01-01 00:02:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a145</td>\n",
       "      <td>a96</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76511</th>\n",
       "      <td>call</td>\n",
       "      <td>00183331706</td>\n",
       "      <td>+8800186773263</td>\n",
       "      <td>2020-01-01 00:02:23</td>\n",
       "      <td>96.0</td>\n",
       "      <td>a84</td>\n",
       "      <td>a36</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90162</th>\n",
       "      <td>text</td>\n",
       "      <td>+8800189721427</td>\n",
       "      <td>00188688509</td>\n",
       "      <td>2020-01-01 00:03:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a261</td>\n",
       "      <td>a268</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      txn_type       caller_id    recipient_id           timestamp  duration  \\\n",
       "76053     call     00180479117     00186879451 2020-01-01 00:00:42     253.0   \n",
       "55660     text     00181616517     00185633871 2020-01-01 00:02:04       NaN   \n",
       "49363     text     00189653293     00186624501 2020-01-01 00:02:12       NaN   \n",
       "76511     call     00183331706  +8800186773263 2020-01-01 00:02:23      96.0   \n",
       "90162     text  +8800189721427     00188688509 2020-01-01 00:03:05       NaN   \n",
       "\n",
       "      caller_antenna recipient_antenna international  \n",
       "76053           a101               a54      domestic  \n",
       "55660            a44              a110      domestic  \n",
       "49363           a145               a96      domestic  \n",
       "76511            a84               a36      domestic  \n",
       "90162           a261              a268      domestic  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mobile data usage table\n",
    "np.random.seed(500)\n",
    "num_data_txns = 10000\n",
    "percent_use_data = 0.6\n",
    "\n",
    "subs = pd.read_csv(synthetic_data_folder / 'subscribers.csv', dtype={'subscriber_id': str})\n",
    "subs = subs.sample(frac=1, replace=False)[:int(len(subs)*percent_use_data)]\n",
    "mobiledata = subs.sample(num_data_txns, replace=True).rename(columns={'subscriber_id': 'caller_id'})\n",
    "mobiledata['volume'] = np.random.normal(100, 20, num_data_txns)\n",
    "\n",
    "start = pd.to_datetime('2020-01-01 00:00:00')\n",
    "end = pd.to_datetime('2020-03-01 00:00:00')\n",
    "seconds = ((end - start).days)*24*60*60\n",
    "timestamps = [start + pd.Timedelta(seconds=np.random.randint(0, seconds)) for _ in range(num_data_txns)]\n",
    "mobiledata['timestamp'] = timestamps\n",
    "mobiledata = mobiledata.sort_values('timestamp', ascending=True)\n",
    "\n",
    "mobiledata.to_csv(synthetic_data_folder / 'mobiledata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caller_id</th>\n",
       "      <th>volume</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>00186705257</td>\n",
       "      <td>91.386518</td>\n",
       "      <td>2020-01-01 00:01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>00186860952</td>\n",
       "      <td>118.898352</td>\n",
       "      <td>2020-01-01 00:02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>00186100853</td>\n",
       "      <td>67.682133</td>\n",
       "      <td>2020-01-01 00:16:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>+8800182177053</td>\n",
       "      <td>65.525068</td>\n",
       "      <td>2020-01-01 00:23:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>00183331706</td>\n",
       "      <td>99.461383</td>\n",
       "      <td>2020-01-01 00:41:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          caller_id      volume           timestamp\n",
       "163     00186705257   91.386518 2020-01-01 00:01:15\n",
       "211     00186860952  118.898352 2020-01-01 00:02:27\n",
       "507     00186100853   67.682133 2020-01-01 00:16:33\n",
       "105  +8800182177053   65.525068 2020-01-01 00:23:37\n",
       "713     00183331706   99.461383 2020-01-01 00:41:44"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobiledata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recharges table\n",
    "np.random.seed(600)\n",
    "num_recharge_txns = 10000\n",
    "percent_use_recharges = 0.8\n",
    "\n",
    "subs = pd.read_csv(synthetic_data_folder / 'subscribers.csv', dtype={'subscriber_id': str}).rename(columns={'subscriber_id': 'caller_id'})\n",
    "subs = subs.sample(frac=1, replace=False)[:int(len(subs)*percent_use_recharges)]\n",
    "recharges = subs.sample(num_recharge_txns, replace=True)\n",
    "recharges['amount'] = np.random.randint(0, 100, num_recharge_txns)\n",
    "\n",
    "start = pd.to_datetime('2020-01-01 00:00:00')\n",
    "end = pd.to_datetime('2020-03-01 00:00:00')\n",
    "seconds = ((end - start).days)*24*60*60\n",
    "timestamps = [start + pd.Timedelta(seconds=np.random.randint(0, seconds)) for _ in range(num_data_txns)]\n",
    "recharges['timestamp'] = timestamps\n",
    "recharges = recharges.sort_values('timestamp', ascending=True)\n",
    "\n",
    "recharges.to_csv(synthetic_data_folder / 'recharges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caller_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>00184244668</td>\n",
       "      <td>96</td>\n",
       "      <td>2020-01-01 00:02:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>00189105889</td>\n",
       "      <td>73</td>\n",
       "      <td>2020-01-01 00:04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>00186531427</td>\n",
       "      <td>98</td>\n",
       "      <td>2020-01-01 00:08:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>00184550445</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-01-01 00:14:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>00183228495</td>\n",
       "      <td>76</td>\n",
       "      <td>2020-01-01 00:24:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       caller_id  amount           timestamp\n",
       "257  00184244668      96 2020-01-01 00:02:47\n",
       "426  00189105889      73 2020-01-01 00:04:33\n",
       "747  00186531427      98 2020-01-01 00:08:36\n",
       "74   00184550445       7 2020-01-01 00:14:37\n",
       "684  00183228495      76 2020-01-01 00:24:36"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recharges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate mobile money table\n",
    "np.random.seed(700)\n",
    "num_mm_txns = 10000\n",
    "percent_use_mm = 0.7\n",
    "txn_types = ['cashin', 'cashout', 'p2p', 'billpay', 'other']\n",
    "txn_probs = [.2, .2, .4, .1, .1]\n",
    "\n",
    "subs = pd.read_csv(synthetic_data_folder / 'subscribers.csv', dtype={'subscriber_id': str})\n",
    "subs = subs.sample(frac=1, replace=False)[:int(len(subs)*percent_use_mm)]\n",
    "subs = subs['subscriber_id'].values.flatten()\n",
    "\n",
    "start = pd.to_datetime('2020-01-01 00:00:00')\n",
    "end = pd.to_datetime('2020-03-01 00:00:00')\n",
    "seconds = ((end - start).days)*24*60*60\n",
    "\n",
    "mm_txns = []\n",
    "while len(mm_txns) < num_mm_txns:\n",
    "    txn_type = np.random.choice(txn_types, p=txn_probs)\n",
    "    caller = np.random.choice(subs)\n",
    "    if txn_type in ['p2p', 'billpay', 'other']:\n",
    "        recipient = np.random.choice(subs)\n",
    "    else:\n",
    "        recipient = np.nan\n",
    "    timedif = np.random.randint(0, seconds)\n",
    "    timestamp = start + pd.Timedelta(seconds=timedif)\n",
    "    if caller != recipient:\n",
    "        mm_txns.append([txn_type, caller, recipient, timestamp])\n",
    "\n",
    "mm_txns = pd.DataFrame(mm_txns, columns = ['txn_type', 'caller_id', 'recipient_id', 'timestamp'])\n",
    "mm_txns['amount'] = np.random.normal(50, 10, num_mm_txns)\n",
    "#mm_txns['amount'] = mm_txns\\\n",
    "#    .apply(lambda row: -row['amount'] if row['txn_type'] == 'cashout' \n",
    "#           else row['amount'], axis=1)\n",
    "mm_txns['sender_balance_before'] = np.random.normal(200, 40, num_mm_txns)\n",
    "mm_txns['sender_balance_after'] = mm_txns\\\n",
    "    .apply(lambda row: row['sender_balance_before'] + row['amount'] if row['txn_type'] == 'cashin'\n",
    "          else row['sender_balance_before'] - row['amount'], axis=1)\n",
    "mm_txns['recipient_balance_before'] = np.random.normal(200, 40, num_mm_txns)\n",
    "mm_txns['recipient_balance_before'] = mm_txns\\\n",
    "    .apply(lambda row: np.nan if row['txn_type'] in ['cashin', 'cashout'] else row['recipient_balance_before'],\n",
    "          axis=1)\n",
    "mm_txns['recipient_balance_after'] = mm_txns['recipient_balance_before'] + mm_txns['amount']\n",
    "mm_txns = mm_txns.sort_values('timestamp', ascending=True)\n",
    "\n",
    "mm_txns.to_csv(synthetic_data_folder / 'mobilemoney.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn_type</th>\n",
       "      <th>caller_id</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>sender_balance_before</th>\n",
       "      <th>sender_balance_after</th>\n",
       "      <th>recipient_balance_before</th>\n",
       "      <th>recipient_balance_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8557</th>\n",
       "      <td>p2p</td>\n",
       "      <td>00180231659</td>\n",
       "      <td>00180788525</td>\n",
       "      <td>2020-01-01 00:15:51</td>\n",
       "      <td>55.163313</td>\n",
       "      <td>324.218747</td>\n",
       "      <td>269.055434</td>\n",
       "      <td>112.544987</td>\n",
       "      <td>167.708300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9904</th>\n",
       "      <td>cashout</td>\n",
       "      <td>00184232415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01 00:18:59</td>\n",
       "      <td>81.860999</td>\n",
       "      <td>185.576198</td>\n",
       "      <td>103.715199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5188</th>\n",
       "      <td>cashin</td>\n",
       "      <td>00180474788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01 00:28:17</td>\n",
       "      <td>29.225047</td>\n",
       "      <td>98.638294</td>\n",
       "      <td>127.863341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6900</th>\n",
       "      <td>p2p</td>\n",
       "      <td>00182560474</td>\n",
       "      <td>00182475956</td>\n",
       "      <td>2020-01-01 00:28:29</td>\n",
       "      <td>45.561912</td>\n",
       "      <td>248.718378</td>\n",
       "      <td>203.156466</td>\n",
       "      <td>212.016381</td>\n",
       "      <td>257.578293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>cashout</td>\n",
       "      <td>00186770808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01 00:31:03</td>\n",
       "      <td>55.040771</td>\n",
       "      <td>150.886443</td>\n",
       "      <td>95.845672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     txn_type    caller_id recipient_id           timestamp     amount  \\\n",
       "8557      p2p  00180231659  00180788525 2020-01-01 00:15:51  55.163313   \n",
       "9904  cashout  00184232415          NaN 2020-01-01 00:18:59  81.860999   \n",
       "5188   cashin  00180474788          NaN 2020-01-01 00:28:17  29.225047   \n",
       "6900      p2p  00182560474  00182475956 2020-01-01 00:28:29  45.561912   \n",
       "2245  cashout  00186770808          NaN 2020-01-01 00:31:03  55.040771   \n",
       "\n",
       "      sender_balance_before  sender_balance_after  recipient_balance_before  \\\n",
       "8557             324.218747            269.055434                112.544987   \n",
       "9904             185.576198            103.715199                       NaN   \n",
       "5188              98.638294            127.863341                       NaN   \n",
       "6900             248.718378            203.156466                212.016381   \n",
       "2245             150.886443             95.845672                       NaN   \n",
       "\n",
       "      recipient_balance_after  \n",
       "8557               167.708300  \n",
       "9904                      NaN  \n",
       "5188                      NaN  \n",
       "6900               257.578293  \n",
       "2245                      NaN  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_txns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop and read before continuing**\n",
    "\n",
    "At this point, go run the featurization quickstart notebook and then copy its output (synthetic_outputs/featurizer/datasets/features.csv) to synthetic_data/features.csv. They'll probably be written to synthetic_output/featurizer/datasets/features.csv by the featurizer notebook, so copy from there. If you don't do that copying step, the features and labels won't match the other data - this could create confusing and misleading conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate labels (using the features dataset which will be read in by the ML module). \n",
    "np.random.seed(1)\n",
    "feats = pd.read_csv('../synthetic_data/features.csv')\n",
    "feats['label'] = feats['number_of_interactions_alldir_allweek_allday_call']**2 + \\\n",
    "    feats['active_days_weekend_day']**3 + \\\n",
    "    feats['location_count(regions)']**5\n",
    "\n",
    "explained_std = feats['label'].std()\n",
    "\n",
    "feats['label'] = feats['label'] + np.random.randint(0, int(explained_std), len(feats))\n",
    "feats = feats[['name', 'label']].sample(50, replace=True, random_state=2)\n",
    "feats['weight'] = (np.random.rand(1, len(feats))*100).flatten()\n",
    "feats.to_csv('../synthetic_data/labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscribers = pd.read_csv('../synthetic_data/subscribers.csv', dtype={'subscriber_id': str})\n",
    "antennas = pd.read_csv('../synthetic_data/antennas.csv')\n",
    "regions = gpd.read_file('../synthetic_data/regions.geojson')\n",
    "prefectures = gpd.read_file('../synthetic_data/prefectures.geojson')\n",
    "subscribers['antenna_id'] = antennas['antenna_id'].drop_duplicates()\\\n",
    "    .sample(len(subscribers), replace=True).values\n",
    "subscribers['tower_id'] = antennas['tower_id'].drop_duplicates()\\\n",
    "    .sample(len(subscribers), replace=True).values\n",
    "subscribers['regions'] = regions['region'].drop_duplicates()\\\n",
    "    .sample(len(subscribers), replace=True).values\n",
    "subscribers['prefectures'] = prefectures['region'].drop_duplicates()\\\n",
    "    .sample(len(subscribers), replace=True).values\n",
    "subscribers.to_csv('../synthetic_data/home_locations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "obs = 1000\n",
    "\n",
    "# Unique IDs\n",
    "uids = np.arange(obs)\n",
    "\n",
    "# Phone numbers\n",
    "strlen = 10\n",
    "subs = []\n",
    "for i in range(obs):\n",
    "    subs.append(''.join(random.choice(string.ascii_lowercase + string.ascii_uppercase) for _ in range(strlen)))\n",
    "    \n",
    "# Consumption\n",
    "consumption = np.random.rand(obs)*50\n",
    "\n",
    "# Binary questions\n",
    "binary_questions = 10\n",
    "binary_data = pd.DataFrame([np.round(np.random.rand(obs)) for i in range(1, 1+binary_questions)]).T\n",
    "binary_columns = ['bin' + str(i) for i in range(binary_questions)]\n",
    "binary_data.columns = binary_columns\n",
    "\n",
    "# Continuous questions\n",
    "continuous_questions = 10\n",
    "continuous_data = pd.DataFrame([np.random.rand(obs)*i for i in range(1, 1+continuous_questions)]).T\n",
    "continuous_columns = ['con' + str(i) for i in range(continuous_questions)]\n",
    "continuous_data.columns = continuous_columns\n",
    "\n",
    "# Categorical questions\n",
    "categorical_questions = 10\n",
    "categorical_data = pd.DataFrame([np.random.randint(low=0, high=10, size=obs) for i in \\\n",
    "                                 range(1, 1+categorical_questions)]).T\n",
    "categorical_columns = ['cat' + str(i) for i in range(categorical_questions)]\n",
    "categorical_data.columns = categorical_columns\n",
    "\n",
    "# Combine data\n",
    "data = pd.concat([binary_data, continuous_data, categorical_data], axis=1)\n",
    "data['unique_id'] = uids\n",
    "data['consumption'] = consumption\n",
    "data['weight'] = np.random.rand(obs)*10\n",
    "data['phone_number'] = subs\n",
    "data = data[['unique_id', 'phone_number', 'weight', 'consumption'] + binary_columns + continuous_columns + \\\n",
    "            categorical_columns]\n",
    "\n",
    "# Add some missing data\n",
    "for col in ['consumption'] + binary_columns + categorical_columns + continuous_columns:\n",
    "    data[col] = data[col].apply(lambda x: np.nan if np.random.rand() < .01 else x)\n",
    "\n",
    "# Save to file\n",
    "data.to_csv('survey.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_cider",
   "language": "python",
   "name": "conda_cider"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
