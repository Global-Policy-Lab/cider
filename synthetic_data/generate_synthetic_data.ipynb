{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_folder = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OBJECTID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28604/1129538637.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshapefile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynthetic_data_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/regions.geojson'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mshapefile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshapefile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdissolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'OBJECTID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpolygon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshapefile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/poetry/lib/python3.8/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36mdissolve\u001b[0;34m(self, by, aggfunc, as_index, level, sort, observed, dropna)\u001b[0m\n\u001b[1;32m   1491\u001b[0m         \u001b[0;31m# Process non-spatial component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m         \u001b[0maggregated_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mgroupby_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m         \u001b[0;31m# Process spatial component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/poetry/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   7629\u001b[0m         \u001b[0;31m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7630\u001b[0m         \u001b[0;31m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7631\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   7632\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7633\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/poetry/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    890\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/poetry/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    860\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OBJECTID'"
     ]
    }
   ],
   "source": [
    "# Generate table of towers\n",
    "np.random.seed(100)\n",
    "num_towers = 100\n",
    "\n",
    "shapefile = gpd.read_file(synthetic_data_folder + '/regions.geojson')\n",
    "shapefile = shapefile.dissolve(by='OBJECTID')\n",
    "polygon = shapefile['geometry'][0]\n",
    "\n",
    "minx, miny, maxx, maxy = polygon.bounds\n",
    "lats, lons = [], []\n",
    "while len(lats) < num_towers:\n",
    "    point = Point(np.random.uniform(minx, maxx), np.random.uniform(miny, maxy))\n",
    "    if polygon.contains(point):\n",
    "        lats.append(point.y)\n",
    "        lons.append(point.x)\n",
    "points = pd.DataFrame([lats, lons]).T\n",
    "points.columns = ['latitude', 'longitude']\n",
    "points['tower_id'] = range(len(points))\n",
    "points['tower_id'] = points['tower_id'].apply(lambda x: 't' + str(x))\n",
    "points.to_csv(synthetic_data_folder + '/towers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate table of antennas\n",
    "np.random.seed(200)\n",
    "num_extra_antennas = 10\n",
    "\n",
    "antennas = []\n",
    "towers = pd.read_csv(synthetic_data_folder + '/towers.csv')\n",
    "towerids = towers['tower_id'].values\n",
    "for towerid in towerids:\n",
    "    num_antennas = np.random.randint(1, 6)\n",
    "    for i in range(num_antennas):\n",
    "        antennas.append(towerid)\n",
    "antennas = pd.DataFrame(antennas)\n",
    "antennas.columns = ['tower_id']\n",
    "antennas['antenna_id'] = range(len(antennas))\n",
    "antennas['antenna_id'] = antennas['antenna_id'].apply(lambda x: 'a' + str(x))\n",
    "antennas = antennas[['antenna_id', 'tower_id']]\n",
    "max_antenna = int(antennas['antenna_id'].values[-1][1:])\n",
    "antennas_notower = ['a' + str(i) for i in range(max_antenna+1, max_antenna+1+num_extra_antennas)]\n",
    "antennas_notower = pd.DataFrame([antennas_notower, [np.nan for _ in antennas_notower]]).T\n",
    "antennas_notower.columns = ['antenna_id', 'tower_id']\n",
    "antennas = pd.concat([antennas, antennas_notower])\n",
    "antennas.to_csv(synthetic_data_folder + '/antennas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate table of subscribers\n",
    "num_subscribers = 1000\n",
    "strlen = 10\n",
    "random.seed(300)\n",
    "\n",
    "subs = []\n",
    "for i in range(num_subscribers):\n",
    "    subs.append(''.join(random.choice(string.ascii_lowercase + string.ascii_uppercase) for _ in range(strlen)))\n",
    "subs = pd.DataFrame(subs)\n",
    "subs.columns = ['subscriber_id']\n",
    "subs.to_csv(synthetic_data_folder + '/subscribers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate call/SMS table\n",
    "np.random.seed(400)\n",
    "num_txns = 100000\n",
    "\n",
    "subs = pd.read_csv(synthetic_data_folder + '/subscribers.csv')['subscriber_id'].values.flatten()\n",
    "antenna_dict = pd.read_csv(synthetic_data_folder + '/antennas.csv')\n",
    "antennas = antenna_dict['antenna_id'].values.flatten()\n",
    "towers = pd.read_csv(synthetic_data_folder + '/towers.csv')\n",
    "\n",
    "start = pd.to_datetime('2020-01-01 00:00:00')\n",
    "end = pd.to_datetime('2020-03-01 00:00:00')\n",
    "seconds = ((end - start).days)*24*60*60\n",
    "\n",
    "txns = []\n",
    "while len(txns) < num_txns:\n",
    "    caller = np.random.choice(subs)\n",
    "    recipient = np.random.choice(subs)\n",
    "    caller_antenna = np.random.choice(antennas)\n",
    "    recipient_antenna = np.random.choice(antennas)\n",
    "    international = np.random.choice(['domestic', 'international', 'other'], p=[.98, .01, .01])\n",
    "    if np.random.randint(0, 10) == 0:\n",
    "        caller_antenna = np.nan\n",
    "    if np.random.randint(0, 10) == 0:\n",
    "        recipient_antenna = np.nan\n",
    "    timedif = np.random.randint(0, seconds)\n",
    "    timestamp = start + pd.Timedelta(seconds=timedif)\n",
    "    if caller != recipient:\n",
    "        txns.append([caller, recipient, caller_antenna, recipient_antenna, timestamp, international])\n",
    "\n",
    "txns = pd.DataFrame(txns)\n",
    "txns.columns = ['caller_id', 'recipient_id', 'caller_antenna', 'recipient_antenna', 'timestamp', 'international']\n",
    "txns['interaction'] = np.random.choice(['voice', 'sms'], size=len(txns))\n",
    "txns['duration'] = np.random.randint(0, 300, size=len(txns))\n",
    "txns['duration'] = txns.apply(lambda row: row['duration'] if row['interaction'] == 'voice' else np.nan, axis=1)\n",
    "txns = txns.sort_values('timestamp', ascending=True)\n",
    "txns = txns[['interaction', 'caller_id', 'recipient_id', 'timestamp', 'duration', 'caller_antenna', \n",
    "             'recipient_antenna', 'international']]\n",
    "\n",
    "txns.to_csv(synthetic_data_folder + '/cdr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction</th>\n",
       "      <th>caller_id</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>caller_antenna</th>\n",
       "      <th>recipient_antenna</th>\n",
       "      <th>international</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76053</th>\n",
       "      <td>voice</td>\n",
       "      <td>ptudOnjdRU</td>\n",
       "      <td>hZvsVsiGbO</td>\n",
       "      <td>2020-01-01 00:00:42</td>\n",
       "      <td>253.0</td>\n",
       "      <td>a101</td>\n",
       "      <td>a54</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55660</th>\n",
       "      <td>sms</td>\n",
       "      <td>UGDojtMoWq</td>\n",
       "      <td>lpAchcvhBO</td>\n",
       "      <td>2020-01-01 00:02:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a44</td>\n",
       "      <td>a110</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49363</th>\n",
       "      <td>sms</td>\n",
       "      <td>sQGOjnDvvt</td>\n",
       "      <td>PGiqQSpzov</td>\n",
       "      <td>2020-01-01 00:02:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a145</td>\n",
       "      <td>a96</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76511</th>\n",
       "      <td>voice</td>\n",
       "      <td>oPbUuvHBgi</td>\n",
       "      <td>IdYycyWmjl</td>\n",
       "      <td>2020-01-01 00:02:23</td>\n",
       "      <td>96.0</td>\n",
       "      <td>a84</td>\n",
       "      <td>a36</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90162</th>\n",
       "      <td>sms</td>\n",
       "      <td>pSwWTbHbug</td>\n",
       "      <td>sRLqqorjkH</td>\n",
       "      <td>2020-01-01 00:03:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a261</td>\n",
       "      <td>a268</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      interaction   caller_id recipient_id           timestamp  duration  \\\n",
       "76053       voice  ptudOnjdRU   hZvsVsiGbO 2020-01-01 00:00:42     253.0   \n",
       "55660         sms  UGDojtMoWq   lpAchcvhBO 2020-01-01 00:02:04       NaN   \n",
       "49363         sms  sQGOjnDvvt   PGiqQSpzov 2020-01-01 00:02:12       NaN   \n",
       "76511       voice  oPbUuvHBgi   IdYycyWmjl 2020-01-01 00:02:23      96.0   \n",
       "90162         sms  pSwWTbHbug   sRLqqorjkH 2020-01-01 00:03:05       NaN   \n",
       "\n",
       "      caller_antenna recipient_antenna international  \n",
       "76053           a101               a54      domestic  \n",
       "55660            a44              a110      domestic  \n",
       "49363           a145               a96      domestic  \n",
       "76511            a84               a36      domestic  \n",
       "90162           a261              a268      domestic  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mobile data usage table\n",
    "np.random.seed(500)\n",
    "num_data_txns = 10000\n",
    "percent_use_data = 0.6\n",
    "\n",
    "subs = pd.read_csv(synthetic_data_folder + '/subscribers.csv')\n",
    "subs = subs.sample(frac=1, replace=False)[:int(len(subs)*percent_use_data)]\n",
    "mobiledata = subs.sample(num_data_txns, replace=True)\n",
    "mobiledata['volume'] = np.random.normal(100, 20, num_data_txns)\n",
    "\n",
    "start = pd.to_datetime('2020-01-01 00:00:00')\n",
    "end = pd.to_datetime('2020-03-01 00:00:00')\n",
    "seconds = ((end - start).days)*24*60*60\n",
    "timestamps = [start + pd.Timedelta(seconds=np.random.randint(0, seconds)) for _ in range(num_data_txns)]\n",
    "mobiledata['timestamp'] = timestamps\n",
    "mobiledata = mobiledata.sort_values('timestamp', ascending=True)\n",
    "\n",
    "mobiledata.to_csv(synthetic_data_folder + '/mobiledata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subscriber_id</th>\n",
       "      <th>volume</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>MJKWEawMBC</td>\n",
       "      <td>91.386518</td>\n",
       "      <td>2020-01-01 00:01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>yofaYDcyWJ</td>\n",
       "      <td>118.898352</td>\n",
       "      <td>2020-01-01 00:02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>XstqtfmwLR</td>\n",
       "      <td>67.682133</td>\n",
       "      <td>2020-01-01 00:16:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>ZxDgrIqzha</td>\n",
       "      <td>65.525068</td>\n",
       "      <td>2020-01-01 00:23:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>oPbUuvHBgi</td>\n",
       "      <td>99.461383</td>\n",
       "      <td>2020-01-01 00:41:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subscriber_id      volume           timestamp\n",
       "163    MJKWEawMBC   91.386518 2020-01-01 00:01:15\n",
       "211    yofaYDcyWJ  118.898352 2020-01-01 00:02:27\n",
       "507    XstqtfmwLR   67.682133 2020-01-01 00:16:33\n",
       "105    ZxDgrIqzha   65.525068 2020-01-01 00:23:37\n",
       "713    oPbUuvHBgi   99.461383 2020-01-01 00:41:44"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobiledata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top-ups table\n",
    "np.random.seed(600)\n",
    "num_topup_txns = 10000\n",
    "percent_use_topups = 0.8\n",
    "\n",
    "subs = pd.read_csv(synthetic_data_folder + '/subscribers.csv')\n",
    "subs = subs.sample(frac=1, replace=False)[:int(len(subs)*percent_use_topups)]\n",
    "topups = subs.sample(num_topup_txns, replace=True)\n",
    "topups['amount'] = np.random.randint(0, 100, num_topup_txns)\n",
    "\n",
    "start = pd.to_datetime('2020-01-01 00:00:00')\n",
    "end = pd.to_datetime('2020-03-01 00:00:00')\n",
    "seconds = ((end - start).days)*24*60*60\n",
    "timestamps = [start + pd.Timedelta(seconds=np.random.randint(0, seconds)) for _ in range(num_data_txns)]\n",
    "topups['timestamp'] = timestamps\n",
    "topups = topups.sort_values('timestamp', ascending=True)\n",
    "\n",
    "topups.to_csv(synthetic_data_folder + '/topups.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subscriber_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>WzwHpoldPp</td>\n",
       "      <td>96</td>\n",
       "      <td>2020-01-01 00:02:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>xkThzuCDAY</td>\n",
       "      <td>73</td>\n",
       "      <td>2020-01-01 00:04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>OtFfOxcGMu</td>\n",
       "      <td>98</td>\n",
       "      <td>2020-01-01 00:08:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>pjjlDwunYH</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-01-01 00:14:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>RBDklSsXkt</td>\n",
       "      <td>76</td>\n",
       "      <td>2020-01-01 00:24:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subscriber_id  amount           timestamp\n",
       "257    WzwHpoldPp      96 2020-01-01 00:02:47\n",
       "426    xkThzuCDAY      73 2020-01-01 00:04:33\n",
       "747    OtFfOxcGMu      98 2020-01-01 00:08:36\n",
       "74     pjjlDwunYH       7 2020-01-01 00:14:37\n",
       "684    RBDklSsXkt      76 2020-01-01 00:24:36"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mobile money table\n",
    "np.random.seed(700)\n",
    "num_mm_txns = 10000\n",
    "percent_use_mm = 0.7\n",
    "txn_types = ['cashin', 'cashout', 'p2p', 'billpay', 'other']\n",
    "txn_probs = [.2, .2, .4, .1, .1]\n",
    "\n",
    "subs = pd.read_csv(synthetic_data_folder + '/subscribers.csv')\n",
    "subs = subs.sample(frac=1, replace=False)[:int(len(subs)*percent_use_mm)]\n",
    "subs = subs['subscriber_id'].values.flatten()\n",
    "\n",
    "start = pd.to_datetime('2020-01-01 00:00:00')\n",
    "end = pd.to_datetime('2020-03-01 00:00:00')\n",
    "seconds = ((end - start).days)*24*60*60\n",
    "\n",
    "mm_txns = []\n",
    "while len(mm_txns) < num_mm_txns:\n",
    "    txn_type = np.random.choice(txn_types, p=txn_probs)\n",
    "    caller = np.random.choice(subs)\n",
    "    if txn_type in ['p2p', 'billpay', 'other']:\n",
    "        recipient = np.random.choice(subs)\n",
    "    else:\n",
    "        recipient = np.nan\n",
    "    timedif = np.random.randint(0, seconds)\n",
    "    timestamp = start + pd.Timedelta(seconds=timedif)\n",
    "    if caller != recipient:\n",
    "        mm_txns.append([txn_type, caller, recipient, timestamp])\n",
    "\n",
    "mm_txns = pd.DataFrame(mm_txns, columns = ['txn_type', 'sender', 'recipient', 'timestamp'])\n",
    "mm_txns['amount'] = np.random.normal(50, 10, num_mm_txns)\n",
    "#mm_txns['amount'] = mm_txns\\\n",
    "#    .apply(lambda row: -row['amount'] if row['txn_type'] == 'cashout' \n",
    "#           else row['amount'], axis=1)\n",
    "mm_txns['sender_balance_before'] = np.random.normal(200, 40, num_mm_txns)\n",
    "mm_txns['sender_balance_after'] = mm_txns\\\n",
    "    .apply(lambda row: row['sender_balance_before'] + row['amount'] if row['txn_type'] == 'cashin'\n",
    "          else row['sender_balance_before'] - row['amount'], axis=1)\n",
    "mm_txns['recipient_balance_before'] = np.random.normal(200, 40, num_mm_txns)\n",
    "mm_txns['recipient_balance_before'] = mm_txns\\\n",
    "    .apply(lambda row: np.nan if row['txn_type'] in ['cashin', 'cashout'] else row['recipient_balance_before'],\n",
    "          axis=1)\n",
    "mm_txns['recipient_balance_after'] = mm_txns['recipient_balance_before'] + mm_txns['amount']\n",
    "mm_txns = mm_txns.sort_values('timestamp', ascending=True)\n",
    "\n",
    "mm_txns.to_csv(synthetic_data_folder + '/mobilemoney.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "feats = pd.read_csv('../outputs/featurizer/datasets/features.csv')\n",
    "feats['label'] = feats['cdr_reporting__number_of_records']**2 + \\\n",
    "    feats['cdr_active_days__weekend__day__callandtext']**3 + \\\n",
    "    feats['location_count(regions)']**5\n",
    "feats['label'] = feats['label'] + np.random.randint(0, 50000, len(feats))\n",
    "# feats = feats[['name', 'label']].sample(50, replace=True, random_state=2)\n",
    "feats = feats[['name', 'label']]\n",
    "feats['weight'] = (np.random.rand(1, len(feats))*100).flatten()\n",
    "feats.to_csv('../synthetic_data/labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscribers = pd.read_csv('../synthetic_data/subscribers.csv')\n",
    "antennas = pd.read_csv('../synthetic_data/antennas.csv')\n",
    "regions = gpd.read_file('../synthetic_data/regions.geojson')\n",
    "prefectures = gpd.read_file('../synthetic_data/prefectures.geojson')\n",
    "subscribers['antenna_id'] = antennas['antenna_id'].drop_duplicates()\\\n",
    "    .sample(len(subscribers), replace=True).values\n",
    "subscribers['tower_id'] = antennas['tower_id'].drop_duplicates()\\\n",
    "    .sample(len(subscribers), replace=True).values\n",
    "subscribers['regions'] = regions['region'].drop_duplicates()\\\n",
    "    .sample(len(subscribers), replace=True).values\n",
    "subscribers['prefectures'] = prefectures['region'].drop_duplicates()\\\n",
    "    .sample(len(subscribers), replace=True).values\n",
    "subscribers.to_csv('../synthetic_data/home_locations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "obs = 1000\n",
    "\n",
    "# Unique IDs\n",
    "uids = np.arange(obs)\n",
    "\n",
    "# Phone numbers\n",
    "strlen = 10\n",
    "subs = []\n",
    "for i in range(obs):\n",
    "    subs.append(''.join(random.choice(string.ascii_lowercase + string.ascii_uppercase) for _ in range(strlen)))\n",
    "    \n",
    "# Consumption\n",
    "consumption = np.random.rand(obs)*50\n",
    "\n",
    "# Binary questions\n",
    "binary_questions = 10\n",
    "binary_data = pd.DataFrame([np.round(np.random.rand(obs)) for i in range(1, 1+binary_questions)]).T\n",
    "binary_columns = ['bin' + str(i) for i in range(binary_questions)]\n",
    "binary_data.columns = binary_columns\n",
    "\n",
    "# Continuous questions\n",
    "continuous_questions = 10\n",
    "continuous_data = pd.DataFrame([np.random.rand(obs)*i for i in range(1, 1+continuous_questions)]).T\n",
    "continuous_columns = ['con' + str(i) for i in range(continuous_questions)]\n",
    "continuous_data.columns = continuous_columns\n",
    "\n",
    "# Categorical questions\n",
    "categorical_questions = 10\n",
    "categorical_data = pd.DataFrame([np.random.randint(low=0, high=10, size=obs) for i in \\\n",
    "                                 range(1, 1+categorical_questions)]).T\n",
    "categorical_columns = ['cat' + str(i) for i in range(categorical_questions)]\n",
    "categorical_data.columns = categorical_columns\n",
    "\n",
    "# Combine data\n",
    "data = pd.concat([binary_data, continuous_data, categorical_data], axis=1)\n",
    "data['unique_id'] = uids\n",
    "data['consumption'] = consumption\n",
    "data['weight'] = np.random.rand(obs)*10\n",
    "data['phone_number'] = subs\n",
    "data = data[['unique_id', 'phone_number', 'weight', 'consumption'] + binary_columns + continuous_columns + \\\n",
    "            categorical_columns]\n",
    "\n",
    "# Add some missing data\n",
    "for col in ['consumption'] + binary_columns + categorical_columns + continuous_columns:\n",
    "    data[col] = data[col].apply(lambda x: np.nan if np.random.rand() < .01 else x)\n",
    "\n",
    "# Save to file\n",
    "data.to_csv('survey.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cider",
   "language": "python",
   "name": "cider"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
