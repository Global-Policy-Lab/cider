{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.regression\n",
    "from joblib import dump\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import sklearn\n",
    "from skmisc.loess import loess\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from ml import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data into right format for cider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/em/.local/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "feats = pd.read_csv('/data/togo_anon/feats/survey_combos/survey2018_cdr2018.csv')\n",
    "feats = feats[[c for c in feats.columns if 'reporting' not in c or  c == 'reporting__number_of_records']]\\\n",
    "    .drop(['_c0', 'canton'], axis=1)\\\n",
    "    .rename({'phone_number':'name'}, axis=1)\n",
    "feats.to_csv('/data/togo_anon/feats/survey_combos/survey2018_cdr2018_cider.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/data/togo_anon/paper/datasets/survey2018.csv')\n",
    "labels = labels[['phone_number', 'weight', 'cons']]\\\n",
    "    .rename({'phone_number':'name', 'cons':'label'}, axis=1)\n",
    "labels.to_csv('/data/togo_anon/surveys/survey2018/survey2018_labels_cider.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations with features: 9421 (9421 unique)\n",
      "Number of observations with labels: 8915 (8821 unique)\n",
      "Number of matched observations: 8915 (8821 unique)\n"
     ]
    }
   ],
   "source": [
    "learner = Learner(cfg_dir='../configs/config_emily.yml')\n",
    "learner.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/em/.conda/envs/cider/lib/python3.7/site-packages/joblib/numpy_pickle.py:103: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "/home/em/.conda/envs/cider/lib/python3.7/site-packages/joblib/numpy_pickle.py:103: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "load_model() got an unexpected keyword argument 'tuned'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-faf012697edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuned_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gradientboosting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cider/ml.py\u001b[0m in \u001b[0;36mtuned_model\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Feature importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cider/ml.py\u001b[0m in \u001b[0;36mfeature_importances\u001b[0;34m(self, model, tuned)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0msubdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/tuned_models/'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtuned\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'/untuned_models/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'feature_importances_'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: load_model() got an unexpected keyword argument 'tuned'"
     ]
    }
   ],
   "source": [
    "learner.tuned_model(model_name='gradientboosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos = learner.oos_predictions(model='gradientboosting', tuned=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r2 score for gradient boosting: %.2f' % \n",
    "      r2_score(oos['true'], oos['predicted'], sample_weight=oos['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.scatter_plot(model_name='gradientboosting', tuned=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/em/.local/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "WARNING:autogluon.core.utils.utils:Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/home/em/cideroutputs/machinelearning/automl_models/autogluon/model\"\n",
      "INFO:root:Presets specified: ['best_quality']\n",
      "INFO:autogluon.tabular.learner.abstract_learner:Values in column 'weight' used as sample weights instead of predictive features. Evaluation will report weighted metrics, so ensure same column exists in test data.\n",
      "INFO:autogluon.tabular.learner.default_learner:Beginning AutoGluon training ... Time limit = 3600s\n",
      "INFO:autogluon.tabular.learner.default_learner:AutoGluon will save models to \"/home/em/cideroutputs/machinelearning/automl_models/autogluon/model/\"\n",
      "INFO:autogluon.tabular.learner.default_learner:AutoGluon Version:  0.2.0\n",
      "INFO:autogluon.tabular.learner.default_learner:Train Data Rows:    8915\n",
      "INFO:autogluon.tabular.learner.default_learner:Train Data Columns: 1041\n",
      "INFO:autogluon.tabular.learner.default_learner:Preprocessing data ...\n",
      "Level 25:autogluon.core.utils.utils:AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "INFO:autogluon.core.utils.utils:\tLabel info (max, min, mean, stddev): (13.31289864781153, 0.363065399699204, 1.51207, 0.64678)\n",
      "Level 25:autogluon.core.utils.utils:\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "INFO:autogluon.tabular.learner.default_learner:Using Feature Generators to preprocess the data ...\n",
      "INFO:autogluon.features.generators.abstract:Fitting AutoMLPipelineFeatureGenerator...\n",
      "INFO:autogluon.features.generators.abstract:\tAvailable Memory:                    394168.63 MB\n",
      "INFO:autogluon.features.generators.abstract:\tTrain Data (Original)  Memory Usage: 74.17 MB (0.0% of available memory)\n",
      "INFO:autogluon.features.generators.abstract:\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "INFO:autogluon.features.generators.abstract:\tStage 1 Generators:\n",
      "INFO:autogluon.features.generators.abstract:\t\tFitting AsTypeFeatureGenerator...\n",
      "INFO:autogluon.features.generators.abstract:\tStage 2 Generators:\n",
      "INFO:autogluon.features.generators.abstract:\t\tFitting FillNaFeatureGenerator...\n",
      "INFO:autogluon.features.generators.abstract:\tStage 3 Generators:\n",
      "INFO:autogluon.features.generators.abstract:\t\tFitting IdentityFeatureGenerator...\n",
      "INFO:autogluon.features.generators.abstract:\tStage 4 Generators:\n",
      "INFO:autogluon.features.generators.abstract:\t\tFitting DropUniqueFeatureGenerator...\n",
      "INFO:autogluon.features.generators.abstract:\tUseless Original Features (Count: 12): ['mm_Cashout__incoming__txn_amount__mean', 'mm_Cashout__incoming__txn_amount__median', 'mm_Cashout__incoming__txn_amount__min', 'mm_Cashout__incoming__txn_amount__max', 'mm_Novissi__incoming__txn_amount__mean', 'mm_Novissi__incoming__txn_amount__median', 'mm_Novissi__incoming__txn_amount__min', 'mm_Novissi__incoming__txn_amount__max', 'mm_Cashout__incoming__correspondent_id__nunique', 'mm_Novissi__incoming__correspondent_id__nunique', 'mm_Cashout__incoming__operator__count', 'mm_Novissi__incoming__operator__count']\n",
      "INFO:autogluon.features.generators.abstract:\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "INFO:autogluon.features.generators.abstract:\t\tThis is typically a feature which has the same value for all rows.\n",
      "INFO:autogluon.features.generators.abstract:\t\tThese features do not need to be present at inference time.\n",
      "INFO:autogluon.features.generators.abstract:\tTypes of features in original data (raw dtype, special dtypes):\n",
      "INFO:autogluon.core.features.feature_metadata:\t\t('float', []) : 1018 | ['cdr_active_days__allweek__allday__callandtext', 'cdr_active_days__allweek__day__callandtext', 'cdr_active_days__allweek__night__callandtext', 'cdr_active_days__weekday__allday__callandtext', 'cdr_active_days__weekday__day__callandtext', ...]\n",
      "INFO:autogluon.core.features.feature_metadata:\t\t('int', [])   :   10 | ['operator', 'count(DISTINCT site_id)', 'count(DISTINCT canton)', 'count(DISTINCT prefecture)', 'count(DISTINCT region)', ...]\n",
      "INFO:autogluon.features.generators.abstract:\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "INFO:autogluon.core.features.feature_metadata:\t\t('float', []) : 1018 | ['cdr_active_days__allweek__allday__callandtext', 'cdr_active_days__allweek__day__callandtext', 'cdr_active_days__allweek__night__callandtext', 'cdr_active_days__weekday__allday__callandtext', 'cdr_active_days__weekday__day__callandtext', ...]\n",
      "INFO:autogluon.core.features.feature_metadata:\t\t('int', [])   :   10 | ['operator', 'count(DISTINCT site_id)', 'count(DISTINCT canton)', 'count(DISTINCT prefecture)', 'count(DISTINCT region)', ...]\n",
      "INFO:autogluon.features.generators.abstract:\t2.0s = Fit runtime\n",
      "INFO:autogluon.features.generators.abstract:\t1028 features in original data used to generate 1028 features in processed data.\n",
      "INFO:autogluon.features.generators.abstract:\tTrain Data (Processed) Memory Usage: 73.32 MB (0.0% of available memory)\n",
      "INFO:autogluon.tabular.learner.default_learner:Data preprocessing and feature engineering runtime = 2.3s ...\n",
      "Level 25:autogluon.tabular.trainer.abstract_trainer:AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\tTo change this, specify the eval_metric argument of fit()\n",
      "INFO:autogluon.tabular.trainer.model_presets.presets:Excluded Model Types: ['FASTAI']\n",
      "INFO:autogluon.tabular.trainer.model_presets.presets:\tFound 'FASTAI' model in hyperparameters, but 'FASTAI' is present in `excluded_model_types` and will be removed.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2397.87s of the 3597.59s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t-0.1441\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.18s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t7.65s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2389.57s of the 3589.35s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t-0.1447\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.14s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t6.53s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2382.51s of the 3582.29s of remaining time.\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 416. Best iteration is:\n",
      "\t[345]\ttrain_set's l2: 0.0944056\ttrain_set's r2: 0.478383\tvalid_set's l2: 0.342537\tvalid_set's r2: -0.232148\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.1099\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t691.78s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.15s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBM_BAG_L1 ... Training model for up to 1690.39s of the 2890.17s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.1099\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t173.76s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.13s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1516.33s of the 2716.11s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.1055\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t45.51s\t = Training runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t4.62s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: CatBoost_BAG_L1 ... Training model for up to 1464.22s of the 2664.0s of remaining time.\n",
      "ERROR:autogluon.tabular.trainer.abstract_trainer:\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "ERROR:autogluon.tabular.trainer.abstract_trainer:\t\t`import catboost` failed.A quick tip is to install via `pip install catboost`.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1464.15s of the 2663.93s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.1218\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t14.12s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t4.9s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: XGBoost_BAG_L1 ... Training model for up to 1443.12s of the 2642.9s of remaining time.\n",
      "ERROR:autogluon.tabular.trainer.abstract_trainer:\tWarning: Exception caused XGBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "ERROR:autogluon.tabular.trainer.abstract_trainer:\t\t`import xgboost` failed. A quick tip is to install via `pip install xgboost`.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 1442.38s of the 2642.16s of remaining time.\n",
      "ERROR:autogluon.tabular.trainer.abstract_trainer:\tWarning: Exception caused NeuralNetMXNet_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "ERROR:autogluon.tabular.trainer.abstract_trainer:\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1442.31s of the 2642.09s of remaining time.\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 35. Best iteration is:\n",
      "\t[35]\ttrain_set's l2: 0.231645\ttrain_set's r2: 0.174975\tvalid_set's l2: 0.387218\tvalid_set's r2: -0.3092\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 36. Best iteration is:\n",
      "\t[36]\ttrain_set's l2: 0.228592\ttrain_set's r2: 0.168148\tvalid_set's l2: 0.335706\tvalid_set's r2: -0.303073\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 234. Best iteration is:\n",
      "\t[199]\ttrain_set's l2: 0.0470668\ttrain_set's r2: 0.658358\tvalid_set's l2: 0.377293\tvalid_set's r2: -0.182418\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 127. Best iteration is:\n",
      "\t[34]\ttrain_set's l2: 0.236853\ttrain_set's r2: 0.185621\tvalid_set's l2: 0.313596\tvalid_set's r2: -0.144881\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 39. Best iteration is:\n",
      "\t[37]\ttrain_set's l2: 0.219915\ttrain_set's r2: 0.196758\tvalid_set's l2: 0.497398\tvalid_set's r2: -0.191895\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 135. Best iteration is:\n",
      "\t[45]\ttrain_set's l2: 0.189281\ttrain_set's r2: 0.278846\tvalid_set's l2: 0.395516\tvalid_set's r2: -0.251988\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 407. Best iteration is:\n",
      "\t[282]\ttrain_set's l2: 0.0290809\ttrain_set's r2: 0.713037\tvalid_set's l2: 0.496982\tvalid_set's r2: -0.163349\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 57. Best iteration is:\n",
      "\t[37]\ttrain_set's l2: 0.205052\ttrain_set's r2: 0.183453\tvalid_set's l2: 0.63903\tvalid_set's r2: -0.175499\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.1045\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t1317.92s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.18s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Completed 1/20 k-fold bagging repeats ...\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1323.58s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.1357\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.48s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.0s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.model_presets.presets:Excluded Model Types: ['FASTAI']\n",
      "INFO:autogluon.tabular.trainer.model_presets.presets:\tFound 'FASTAI' model in hyperparameters, but 'FASTAI' is present in `excluded_model_types` and will be removed.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: KNeighborsUnif_BAG_L2 ... Training model for up to 1323.08s of the 1322.96s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t-0.144\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.14s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t6.08s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: KNeighborsDist_BAG_L2 ... Training model for up to 1316.41s of the 1316.34s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t-0.1443\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.14s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t5.66s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1310.21s of the 1310.13s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.1232\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t951.75s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.19s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: LightGBM_BAG_L2 ... Training model for up to 358.09s of the 358.02s of remaining time.\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 38. Best iteration is:\n",
      "\t[22]\ttrain_set's l2: 0.345965\ttrain_set's r2: -0.120021\tvalid_set's l2: 0.427877\tvalid_set's r2: -0.213874\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 36. Best iteration is:\n",
      "\t[31]\ttrain_set's l2: 0.312764\ttrain_set's r2: -0.0653307\tvalid_set's l2: 0.369121\tvalid_set's r2: -0.262137\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 36. Best iteration is:\n",
      "\t[35]\ttrain_set's l2: 0.281922\ttrain_set's r2: -0.0557495\tvalid_set's l2: 0.623681\tvalid_set's r2: -0.0758134\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 38. Best iteration is:\n",
      "\t[37]\ttrain_set's l2: 0.300464\ttrain_set's r2: -0.0466519\tvalid_set's l2: 0.320825\tvalid_set's r2: -0.155258\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 40. Best iteration is:\n",
      "\t[36]\ttrain_set's l2: 0.284037\ttrain_set's r2: -0.0277788\tvalid_set's l2: 0.672484\tvalid_set's r2: -0.102052\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 42. Best iteration is:\n",
      "\t[16]\ttrain_set's l2: 0.377352\ttrain_set's r2: -0.167583\tvalid_set's l2: 0.31309\tvalid_set's r2: -0.254352\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 41. Best iteration is:\n",
      "\t[27]\ttrain_set's l2: 0.321783\ttrain_set's r2: -0.0968351\tvalid_set's l2: 0.46839\tvalid_set's r2: -0.222001\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 46. Best iteration is:\n",
      "\t[36]\ttrain_set's l2: 0.291856\ttrain_set's r2: -0.0612887\tvalid_set's l2: 0.515074\tvalid_set's r2: -0.152837\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 50. Best iteration is:\n",
      "\t[35]\ttrain_set's l2: 0.299508\ttrain_set's r2: -0.0397002\tvalid_set's l2: 0.400149\tvalid_set's r2: -0.285518\n",
      "INFO:autogluon.tabular.models.lgb.callbacks:\tRan out of time, early stopping on iteration 61. Best iteration is:\n",
      "\t[26]\ttrain_set's l2: 0.33157\ttrain_set's r2: -0.0760106\tvalid_set's l2: 0.403559\tvalid_set's r2: -0.209946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.1172\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t346.71s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.19s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 11.04s of the 10.96s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.099\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t48.81s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t4.65s\t = Validation runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Completed 1/20 k-fold bagging repeats ...\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -44.79s of remaining time.\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.1282\t = Validation r2 score\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.4s\t = Training runtime\n",
      "INFO:autogluon.tabular.trainer.abstract_trainer:\t0.0s\t = Validation runtime\n",
      "INFO:autogluon.tabular.learner.default_learner:AutoGluon training complete, total runtime = 3645.93s ...\n",
      "INFO:root:TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/em/cideroutputs/machinelearning/automl_models/autogluon/model/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished automl training!\n"
     ]
    }
   ],
   "source": [
    "learner.automl(model_name='autogluon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/em/.local/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "oos = learner.oos_predictions('autogluon', type='automl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for AutoML 0.14\n"
     ]
    }
   ],
   "source": [
    "print('R2 score for AutoML %.2f' % r2_score(oos['true'], oos['predicted'], sample_weight=oos['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/em/.local/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "scatter_plot() got an unexpected keyword argument 'tuned'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-74c12b7ac07e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'automl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: scatter_plot() got an unexpected keyword argument 'tuned'"
     ]
    }
   ],
   "source": [
    "learner.scatter_plot(model_name='automl', tuned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cider",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
