{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from featurizer import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer('../synthetic_outputs',\n",
    "                        cdr_fname='../synthetic_data/cdr.csv', \n",
    "                        antennas_fname = '../synthetic_data/antennas.csv',\n",
    "                        topups_fname='../synthetic_data/topups.csv',\n",
    "                        mobiledata_fname='../synthetic_data/mobiledata.csv',\n",
    "                        mobilemoney_fname='../synthetic_data/mobilemoney.csv')\n",
    "\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "topups = pd.read_csv('../synthetic_data/topups.csv')\n",
    "\n",
    "assert featurizer.cdr.count() == len(cdr)\n",
    "\n",
    "featurizer.cdr = featurizer.cdr.union(featurizer.cdr)\n",
    "featurizer.topups = featurizer.topups.union(featurizer.topups)\n",
    "assert featurizer.cdr.count() == 2*len(cdr)\n",
    "assert featurizer.topups.count() == 2*len(topups)\n",
    "\n",
    "featurizer.deduplicate()\n",
    "assert featurizer.cdr.count() == len(cdr)\n",
    "assert featurizer.topups.count() == len(topups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer('../synthetic_outputs',\n",
    "                        cdr_fname='../synthetic_data/cdr.csv', \n",
    "                        topups_fname='../synthetic_data/topups.csv',\n",
    "                        mobiledata_fname='../synthetic_data/mobiledata.csv',\n",
    "                        mobilemoney_fname='../synthetic_data/mobilemoney.csv')\n",
    "\n",
    "for df in [featurizer.cdr, featurizer.topups, featurizer.mobiledata, featurizer.mobilemoney]:\n",
    "    assert df.agg({'day':'min'}).collect()[0][0] == pd.to_datetime('2020-01-01')\n",
    "    assert df.agg({'day':'max'}).collect()[0][0] == pd.to_datetime('2020-02-29')\n",
    "\n",
    "featurizer.filter_dates('2020-01-05', '2020-02-01')\n",
    "for df in [featurizer.cdr, featurizer.topups, featurizer.mobiledata, featurizer.mobilemoney]:\n",
    "    assert df.agg({'day':'min'}).collect()[0][0] == pd.to_datetime('2020-01-05')\n",
    "    assert df.agg({'day':'max'}).collect()[0][0] == pd.to_datetime('2020-02-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Spammers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for number of spammers identified\n",
    "\n",
    "for spammer_threshold in [0, 1, 2]:\n",
    "    \n",
    "    featurizer = Featurizer('../synthetic_outputs',\n",
    "                            cdr_fname='../synthetic_data/cdr.csv', \n",
    "                            topups_fname='../synthetic_data/topups.csv',\n",
    "                            mobiledata_fname='../synthetic_data/mobiledata.csv',\n",
    "                            mobilemoney_fname='../synthetic_data/mobilemoney.csv')\n",
    "\n",
    "    spammers = len(featurizer.remove_spammers(spammer_threshold=spammer_threshold))\n",
    "    \n",
    "    cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "    cdr['timestamp'] = pd.to_datetime(cdr['timestamp'])\n",
    "    grouped = cdr.groupby(['caller_id', 'txn_type'], as_index=False).agg('count')\n",
    "    num_days = (cdr['timestamp'].max() - cdr['timestamp'].min()).days + 1\n",
    "    assert len(grouped[grouped['recipient_id'] > spammer_threshold*num_days]['caller_id'].unique()) == spammers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for removal of spammers\n",
    "\n",
    "spammer_threshold = 1\n",
    "\n",
    "featurizer = Featurizer('../synthetic_outputs',\n",
    "                        cdr_fname='../synthetic_data/cdr.csv', \n",
    "                        topups_fname='../synthetic_data/topups.csv',\n",
    "                        mobiledata_fname='../synthetic_data/mobiledata.csv',\n",
    "                        mobilemoney_fname='../synthetic_data/mobilemoney.csv')\n",
    "\n",
    "spammers = featurizer.remove_spammers(spammer_threshold=spammer_threshold)\n",
    "\n",
    "for df in [featurizer.cdr, featurizer.topups, featurizer.mobiledata, featurizer.mobilemoney]:\n",
    "    \n",
    "    caller_ids = [item[0] for item in featurizer.cdr.select('caller_id').collect()]\n",
    "    assert set(spammers).intersection(set(caller_ids)) == set()\n",
    "    \n",
    "    if 'recipient_id' in df.columns:\n",
    "        recipient_ids = [item[0] for item in featurizer.cdr.select('caller_id').collect()]\n",
    "        assert set(spammers).intersection(set(recipient_ids)) == set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Outlier Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for number of days identified\n",
    "\n",
    "for num_sds in [1, 1.5, 2]:\n",
    "    featurizer = Featurizer('../synthetic_outputs',\n",
    "                            cdr_fname='../synthetic_data/cdr.csv', \n",
    "                            topups_fname='../synthetic_data/topups.csv',\n",
    "                            mobiledata_fname='../synthetic_data/mobiledata.csv',\n",
    "                            mobilemoney_fname='../synthetic_data/mobilemoney.csv')\n",
    "\n",
    "    outliers = [pd.to_datetime(item).tz_localize(None) for item in featurizer.filter_outlier_days(num_sds)]\n",
    "\n",
    "    cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "    cdr['timestamp'] = pd.to_datetime(cdr['timestamp'])\n",
    "    cdr['day'] = cdr['timestamp'].dt.floor('d')\n",
    "    grouped = cdr.groupby('day', as_index=False).agg('count')\n",
    "    u = grouped['txn_type'].mean() + num_sds*grouped['txn_type'].std()\n",
    "    l = grouped['txn_type'].mean() - num_sds*grouped['txn_type'].std()\n",
    "    outliers_manual = grouped[(grouped['txn_type'] < l) | (grouped['txn_type'] > u)]['day'].astype('object')\n",
    "    assert list(outliers_manual.unique()) == outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for removal of days\n",
    "\n",
    "num_sds = 2\n",
    "\n",
    "featurizer = Featurizer('../synthetic_outputs',\n",
    "                        cdr_fname='../synthetic_data/cdr.csv', \n",
    "                        topups_fname='../synthetic_data/topups.csv',\n",
    "                        mobiledata_fname='../synthetic_data/mobiledata.csv',\n",
    "                        mobilemoney_fname='../synthetic_data/mobilemoney.csv')\n",
    "\n",
    "original_counts = []\n",
    "for df in [featurizer.cdr, featurizer.topups, featurizer.mobiledata, featurizer.mobilemoney]:\n",
    "    original_counts.append(df.select('day').distinct().count())\n",
    "    \n",
    "num_outliers = len(featurizer.filter_outlier_days(num_sds))\n",
    "\n",
    "for d, df in enumerate([featurizer.cdr, featurizer.topups, featurizer.mobiledata, featurizer.mobilemoney]):\n",
    "    assert(df.select('day').distinct().count() == original_counts[d] - num_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer('../synthetic_outputs',\n",
    "                        cdr_fname='../synthetic_data/cdr.csv', \n",
    "                        topups_fname='../synthetic_data/topups.csv',\n",
    "                        mobiledata_fname='../synthetic_data/mobiledata.csv',\n",
    "                        mobilemoney_fname='../synthetic_data/mobilemoney.csv')\n",
    "\n",
    "statistics = featurizer.diagnostic_statistics('test_output')\n",
    "\n",
    "for fname, name in [('cdr', 'CDR')]:\n",
    "    \n",
    "    df = pd.read_csv('../synthetic_data/' + fname + '.csv')\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    assert((df['timestamp'].max() - df['timestamp'].min()).days + 1 == statistics[name]['Days'])\n",
    "    assert(len(df) == statistics[name]['Transactions'])\n",
    "    assert(len(df['caller_id'].unique()) == statistics[name]['Subscribers'])\n",
    "    if 'recipient_id' in df.columns:\n",
    "        assert(len(df['recipient_id'].unique()) == statistics[name]['Recipients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer.cdr.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer('../synthetic_outputs',\n",
    "                        cdr_fname='../synthetic_data/cdr.csv', \n",
    "                        topups_fname='../synthetic_data/topups.csv',\n",
    "                        mobiledata_fname='../synthetic_data/mobiledata.csv',\n",
    "                        mobilemoney_fname='../synthetic_data/mobilemoney.csv')\n",
    "\n",
    "featurizer.diagnostic_plots('test_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDR Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from featurizer import *\n",
    "import pandas as pd\n",
    "\n",
    "featurizer = Featurizer('../synthetic_outputs',\n",
    "                        cdr_fname='../synthetic_data/cdr.csv', \n",
    "                        antennas_fname = '../synthetic_data/antennas.csv',\n",
    "                        topups_fname='../synthetic_data/topups.csv',\n",
    "                        mobiledata_fname='../synthetic_data/mobiledata.csv',\n",
    "                        mobilemoney_fname='../synthetic_data/mobilemoney.csv',\n",
    "                        shapefiles={'regions':'../synthetic_data/regions.geojson', \n",
    "                                    'prefectures':'../synthetic_data/prefectures.geojson'})\n",
    "\n",
    "featurizer.cdr_features(bc_chunksize=100, bc_processes=20)\n",
    "featurizer.international_features()\n",
    "featurizer.location_features()\n",
    "featurizer.mobiledata_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CDR...\n",
      "Loading antennas...\n",
      "Warning: 10 antennas missing location\n",
      "Loading recharges...\n",
      "Loading mobile data...\n",
      "Loading mobile money...\n",
      "Calculating CDR features...\n",
      "Calculating international features...\n",
      "Calculating spatial features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/em/.conda/envs/py3/lib/python3.7/site-packages/geopandas/tools/sjoin.py:61: UserWarning: CRS of frames being joined does not match!(None != {'init': 'epsg:4326'})\n",
      "  \"(%s != %s)\" % (left_df.crs, right_df.crs)\n",
      "/home/em/.conda/envs/py3/lib/python3.7/site-packages/geopandas/tools/sjoin.py:61: UserWarning: CRS of frames being joined does not match!(None != {'init': 'epsg:4326'})\n",
      "  \"(%s != %s)\" % (left_df.crs, right_df.crs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating mobile data features...\n",
      "Calculating mobile money features...\n",
      "Calculating recharges features...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from featurizer import *\n",
    "import pandas as pd\n",
    "\n",
    "featurizer = Featurizer('../synthetic_outputs',\n",
    "                        cdr_fname='../synthetic_data/cdr.csv', \n",
    "                        antennas_fname = '../synthetic_data/antennas.csv',\n",
    "                        recharges_fname='../synthetic_data/recharges.csv',\n",
    "                        mobiledata_fname='../synthetic_data/mobiledata.csv',\n",
    "                        mobilemoney_fname='../synthetic_data/mobilemoney.csv',\n",
    "                        shapefiles={'regions':'../synthetic_data/regions.geojson', \n",
    "                                    'prefectures':'../synthetic_data/prefectures.geojson'})\n",
    "\n",
    "featurizer.cdr_features()\n",
    "featurizer.international_features()\n",
    "featurizer.location_features()\n",
    "featurizer.mobiledata_features()\n",
    "featurizer.mobilemoney_features()\n",
    "featurizer.recharges_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "USING column `name` cannot be resolved on the right side of the join. The right-side columns: [mobiledata_caller_id, mobiledata_total_volume, mobiledata_mean_volume, mobiledata_min_volume, mobiledata_max_volume, mobiledata_std_volume, mobiledata_num_days, mobiledata_num_transactions];",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d4eb6b792342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeaturizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cb/featurizer.py\u001b[0m in \u001b[0;36mall_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mall_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mall_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlong_join_pyspark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0msave_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/dataset/features.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cb/utils.py\u001b[0m in \u001b[0;36mlong_join_pyspark\u001b[0;34m(dfs, on, how)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how)\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"how should be basestring\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: USING column `name` cannot be resolved on the right side of the join. The right-side columns: [mobiledata_caller_id, mobiledata_total_volume, mobiledata_mean_volume, mobiledata_min_volume, mobiledata_max_volume, mobiledata_std_volume, mobiledata_num_days, mobiledata_num_transactions];"
     ]
    }
   ],
   "source": [
    "featurizer.all_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
