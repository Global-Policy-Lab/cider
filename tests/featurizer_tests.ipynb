{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.insert(0, '..')\n",
    "from featurizer import *\n",
    "from helpers.utils import *\n",
    "\n",
    "config = '../configs/config_emily.yml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dir('outputs/featurizer')\n",
    "\n",
    "featurizer = Featurizer(config)\n",
    "\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "recharges = pd.read_csv('../synthetic_data/recharges.csv')\n",
    "\n",
    "assert featurizer.cdr.count() == len(cdr)\n",
    "\n",
    "featurizer.cdr = featurizer.cdr.union(featurizer.cdr)\n",
    "featurizer.recharges = featurizer.recharges.union(featurizer.recharges)\n",
    "assert featurizer.cdr.count() == 2*len(cdr)\n",
    "assert featurizer.recharges.count() == 2*len(recharges)\n",
    "\n",
    "featurizer.deduplicate()\n",
    "assert featurizer.cdr.count() == len(cdr)\n",
    "assert featurizer.recharges.count() == len(recharges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer(config)\n",
    "\n",
    "for df in [featurizer.cdr, featurizer.recharges, featurizer.mobiledata, featurizer.mobilemoney]:\n",
    "    assert df.agg({'day':'min'}).collect()[0][0] == pd.to_datetime('2020-01-01')\n",
    "    assert df.agg({'day':'max'}).collect()[0][0] == pd.to_datetime('2020-02-29')\n",
    "\n",
    "featurizer.filter_dates('2020-01-05', '2020-02-01')\n",
    "for df in [featurizer.cdr, featurizer.recharges, featurizer.mobiledata, featurizer.mobilemoney]:\n",
    "    assert df.agg({'day':'min'}).collect()[0][0] == pd.to_datetime('2020-01-05')\n",
    "    assert df.agg({'day':'max'}).collect()[0][0] == pd.to_datetime('2020-02-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Spammers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for number of spammers identified\n",
    "\n",
    "for spammer_threshold in [0, 1.5, 2]:\n",
    "    \n",
    "    featurizer = Featurizer(config)\n",
    "\n",
    "    spammers = len(featurizer.remove_spammers(spammer_threshold=spammer_threshold))\n",
    "    \n",
    "    cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "    cdr['timestamp'] = pd.to_datetime(cdr['timestamp'])\n",
    "    cdr['day'] = cdr['timestamp'].dt.date\n",
    "    grouped = cdr.groupby(['caller_id', 'txn_type']).agg({'day':['count', 'nunique']}).reset_index()\n",
    "    assert len(grouped[grouped['day']['count'] > spammer_threshold*grouped['day']['nunique']]['caller_id'].unique()) == spammers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for removal of spammers\n",
    "\n",
    "spammer_threshold = 1\n",
    "\n",
    "featurizer = Featurizer(config)\n",
    "\n",
    "spammers = featurizer.remove_spammers(spammer_threshold=spammer_threshold)\n",
    "\n",
    "for df in [featurizer.cdr, featurizer.recharges, featurizer.mobiledata, featurizer.mobilemoney]:\n",
    "    \n",
    "    caller_ids = [item[0] for item in featurizer.cdr.select('caller_id').collect()]\n",
    "    assert set(spammers).intersection(set(caller_ids)) == set()\n",
    "    \n",
    "    if 'recipient_id' in df.columns:\n",
    "        recipient_ids = [item[0] for item in featurizer.cdr.select('caller_id').collect()]\n",
    "        assert set(spammers).intersection(set(recipient_ids)) == set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Outlier Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for number of days identified\n",
    "\n",
    "for num_sds in [1, 1.5, 2]:\n",
    "    featurizer = Featurizer(config)\n",
    "\n",
    "    outliers = [pd.to_datetime(item).tz_localize(None) for item in featurizer.filter_outlier_days(num_sds)]\n",
    "\n",
    "    cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "    cdr['timestamp'] = pd.to_datetime(cdr['timestamp'])\n",
    "    cdr['day'] = cdr['timestamp'].dt.floor('d')\n",
    "    grouped = cdr.groupby('day', as_index=False).agg('count')\n",
    "    u = grouped['txn_type'].mean() + num_sds*grouped['txn_type'].std()\n",
    "    l = grouped['txn_type'].mean() - num_sds*grouped['txn_type'].std()\n",
    "    outliers_manual = grouped[(grouped['txn_type'] < l) | (grouped['txn_type'] > u)]['day'].astype('object')\n",
    "    assert list(outliers_manual.unique()) == outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for removal of days\n",
    "\n",
    "num_sds = 2\n",
    "\n",
    "featurizer = Featurizer(config)\n",
    "\n",
    "original_counts = []\n",
    "for df in [featurizer.cdr, featurizer.recharges, featurizer.mobiledata, featurizer.mobilemoney]:\n",
    "    original_counts.append(df.select('day').distinct().count())\n",
    "    \n",
    "num_outliers = len(featurizer.filter_outlier_days(num_sds))\n",
    "\n",
    "for d, df in enumerate([featurizer.cdr, featurizer.recharges, featurizer.mobiledata, featurizer.mobilemoney]):\n",
    "    assert(df.select('day').distinct().count() == original_counts[d] - num_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer(config)\n",
    "\n",
    "statistics = featurizer.diagnostic_statistics('test_output')\n",
    "\n",
    "for fname, name in [('cdr', 'CDR')]:\n",
    "    \n",
    "    df = pd.read_csv('../synthetic_data/' + fname + '.csv')\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    assert((df['timestamp'].max() - df['timestamp'].min()).days + 1 == statistics[name]['Days'])\n",
    "    assert(len(df) == statistics[name]['Transactions'])\n",
    "    assert(len(df['caller_id'].unique()) == statistics[name]['Subscribers'])\n",
    "    if 'recipient_id' in df.columns:\n",
    "        assert(len(df['recipient_id'].unique()) == statistics[name]['Recipients'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer(config)\n",
    "\n",
    "featurizer.diagnostic_plots('test_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDR Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CDR...\n",
      "Loading antennas...\n",
      "Warning: 10 antennas missing location\n",
      "Loading recharges...\n",
      "Loading mobile data...\n",
      "Loading mobile money...\n",
      "Calculating spatial features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/em/.conda/envs/cider/lib/python3.7/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "../featurizer.py:426: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: +init=epsg:4326 +type=crs\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  antennas = gpd.sjoin(antennas, shapefile, op='within', how='left').drop('index_right', axis=1)\n",
      "../featurizer.py:426: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: +init=epsg:4326 +type=crs\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  antennas = gpd.sjoin(antennas, shapefile, op='within', how='left').drop('index_right', axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!\n",
      "25808\n"
     ]
    }
   ],
   "source": [
    "featurizer = Featurizer(config)\n",
    "featurizer.location_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CDR...\n",
      "Loading antennas...\n",
      "Warning: 10 antennas missing location\n",
      "Loading recharges...\n",
      "Loading mobile data...\n",
      "Loading mobile money...\n",
      "Calculating CDR features...\n",
      "Calculating international features...\n",
      "Calculating spatial features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/em/.conda/envs/cider/lib/python3.7/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "../featurizer.py:426: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: +init=epsg:4326 +type=crs\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  antennas = gpd.sjoin(antennas, shapefile, op='within', how='left').drop('index_right', axis=1)\n",
      "../featurizer.py:426: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: +init=epsg:4326 +type=crs\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  antennas = gpd.sjoin(antennas, shapefile, op='within', how='left').drop('index_right', axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating recharges features...\n",
      "Calculating mobile data features...\n",
      "Calculating mobile money features...\n"
     ]
    }
   ],
   "source": [
    "featurizer = Featurizer(config)\n",
    "featurizer.cdr_features()\n",
    "featurizer.international_features()\n",
    "featurizer.location_features()\n",
    "featurizer.recharges_features()\n",
    "featurizer.mobiledata_features()\n",
    "featurizer.mobilemoney_features()\n",
    "featurizer.all_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of records\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "outgoing = cdr.groupby('caller_id').agg('count')\\\n",
    "    [['txn_type']]\n",
    "incoming = cdr.groupby('recipient_id').agg('count')\\\n",
    "    [['txn_type']]\n",
    "txns = pd.concat([outgoing, incoming])\n",
    "txns['caller_id'] = txns.index\n",
    "txn_count = txns.groupby('caller_id').agg('sum')\n",
    "txn_count['name'] = txn_count.index\n",
    "feats = featurizer.features['cdr'].toPandas()\\\n",
    "    [['name', 'cdr_reporting__number_of_records']]\n",
    "feats['cdr_reporting__number_of_records'] = feats['cdr_reporting__number_of_records']\\\n",
    "    .astype('float')\n",
    "merged = txn_count.merge(feats, on='name', how='outer')\n",
    "assert len(merged[merged['txn_type'] != merged['cdr_reporting__number_of_records']]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean call time\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "txns = pd.concat([cdr[['caller_id', 'duration']].rename({'caller_id':'name'}, axis=1), \n",
    "            cdr[['recipient_id', 'duration']].rename({'recipient_id':'name'}, axis=1)])\n",
    "txns = txns.groupby('name', as_index=False).agg('mean')\n",
    "feats = featurizer.features['cdr'].toPandas()\n",
    "feats['cdr_call_duration__allweek__allday__call__mean'] = \\\n",
    "    feats['cdr_call_duration__allweek__allday__call__mean'].astype('float')\n",
    "merged = feats[['name', 'cdr_call_duration__allweek__allday__call__mean']]\\\n",
    "    .merge(txns, on='name')\n",
    "assert len(merged[merged['duration'].astype('int') != \\\n",
    "       merged['cdr_call_duration__allweek__allday__call__mean'].astype('int')]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of contacts\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "txns = cdr[cdr['txn_type'] == 'call']\n",
    "txns = pd.concat([txns[['caller_id', 'recipient_id', 'duration']]\\\n",
    "                      .rename({'caller_id':'name', 'recipient_id':'contact'}, axis=1), \n",
    "                  txns[['caller_id','recipient_id', 'duration']]\\\n",
    "                      .rename({'recipient_id':'name', 'caller_id':'contact'}, axis=1)])\n",
    "contacts = pd.DataFrame(txns.groupby('name')['contact'].nunique())\n",
    "feats = featurizer.features['cdr'].toPandas()\\\n",
    "    [['name', 'cdr_number_of_contacts__allweek__allday__call']]\n",
    "feats['cdr_number_of_contacts__allweek__allday__call'] = \\\n",
    "    feats['cdr_number_of_contacts__allweek__allday__call'].astype('int')\n",
    "merged = feats.merge(contacts, on='name', how='outer')\n",
    "assert len(merged[merged['contact'] != \\\n",
    "                  merged['cdr_number_of_contacts__allweek__allday__call']]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### International Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of outgoing transactions\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "cdr = cdr[cdr['international'] == 'international']\n",
    "feats = featurizer.features['international'].toPandas()\n",
    "inter = cdr.groupby('caller_id', as_index=False).agg('count')[['caller_id', 'txn_type']]\\\n",
    "    .rename({'caller_id':'name'}, axis=1)\n",
    "merged = feats.merge(inter, on='name')\n",
    "assert list(merged['international_all__recipient_id__count'].astype('int')) == \\\n",
    "    list(merged['txn_type'].astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total call duration\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "cdr = cdr[cdr['international'] == 'international']\n",
    "feats = featurizer.features['international'].toPandas()\n",
    "inter = cdr.groupby('caller_id', as_index=False).agg('sum')[['caller_id', 'duration']]\\\n",
    "    .rename({'caller_id':'name'}, axis=1)\n",
    "merged = feats.merge(inter, on='name')\n",
    "assert list(merged['international_call__duration__sum'].fillna(0).astype('float')) == \\\n",
    "    list(merged['duration'].astype('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobile Data Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique days\n",
    "feats = featurizer.features['mobiledata'].toPandas()\n",
    "data = pd.read_csv('../synthetic_data/mobiledata.csv')\n",
    "data['day'] = data['timestamp'].apply(lambda x: x[:10])\n",
    "days = pd.DataFrame(data.groupby('caller_id')['day'].nunique())\n",
    "days['name'] = days.index\n",
    "merged = days.merge(feats, on='name')\n",
    "assert len(merged[merged['day'] != merged['mobiledata_num_days']]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max volume\n",
    "feats = featurizer.features['mobiledata'].toPandas()\n",
    "data = pd.read_csv('../synthetic_data/mobiledata.csv')\n",
    "data = data.groupby('caller_id', as_index=False).agg('max')\\\n",
    "    .rename({'caller_id':'name'}, axis=1)\n",
    "merged = data.merge(feats, on='name')\n",
    "assert list(merged['volume'].astype('int')) == \\\n",
    "    list(merged['mobiledata_max_volume'].astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobile Money Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum outgoing p2p volume\n",
    "feats = featurizer.features['mobilemoney'].toPandas()\n",
    "mm = pd.read_csv('../synthetic_data/mobilemoney.csv')\n",
    "mm = mm[mm['txn_type'] == 'p2p']\n",
    "mm = mm.groupby('caller_id', as_index=False).agg('min')\\\n",
    "    .rename({'caller_id':'name'}, axis=1)\n",
    "merged = mm.merge(feats, on='name', how='outer').fillna(0)\n",
    "assert (merged['mobilemoney_outgoing_p2p_amount_min'].astype('float').round(1) == \\\n",
    "    merged['amount'].astype('float').round(1)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum outgoing p2p volume\n",
    "feats = featurizer.features['mobilemoney'].toPandas()\n",
    "mm = pd.read_csv('../synthetic_data/mobilemoney.csv')\n",
    "outgoing = mm[['caller_id', 'sender_balance_before']]\\\n",
    "    .rename({'caller_id':'name', 'sender_balance_before':'balance'}, axis=1)\n",
    "incoming = mm[['recipient_id', 'recipient_balance_before']]\\\n",
    "    .rename({'recipient_id':'name', 'recipient_balance_before':'balance'}, axis=1)\n",
    "mm = pd.concat([outgoing, incoming])\n",
    "mm = mm.groupby('name', as_index=False).agg('mean')\n",
    "merged = mm.merge(feats, on='name', how='outer').fillna(0)\n",
    "assert (merged['mobilemoney_all_all_balance_before_mean'].astype('float').round(1) == \\\n",
    "    merged['balance'].astype('float').round(1)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recharges Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total recharge\n",
    "feats = featurizer.features['recharges'].toPandas()\n",
    "recharges = pd.read_csv('../synthetic_data/recharges.csv')\\\n",
    "    .rename({'caller_id':'name'}, axis=1)\n",
    "recharges = recharges.groupby('name', as_index=False).agg('sum')\n",
    "merged = recharges.merge(feats, on='name')\n",
    "assert (merged['amount'].astype('float') == merged['recharges_sum'].astype('float')).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/em/.conda/envs/cider/lib/python3.7/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "/home/em/.local/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: +init=epsg:4326 +type=crs\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "feats = featurizer.features['location'].toPandas()\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "antennas = pd.read_csv('../synthetic_data/antennas.csv')\n",
    "antennas = gpd.GeoDataFrame(antennas, geometry=gpd.points_from_xy(antennas['longitude'], antennas['latitude']))\n",
    "antennas.crs = {\"init\":\"epsg:4326\"}\n",
    "prefectures = gpd.read_file('../synthetic_data/prefectures.geojson')\n",
    "antennas = gpd.sjoin(antennas, prefectures, op='within', how='left')[['antenna_id', 'region']]\n",
    "antennas['region'] = antennas['region'].fillna('Unknown')\n",
    "outgoing = cdr[['caller_id', 'caller_antenna']]\\\n",
    "    .rename({'caller_id':'name', 'caller_antenna':'antenna_id'}, axis=1)\\\n",
    "    .merge(antennas, on='antenna_id', how='left')\n",
    "incoming = cdr[['recipient_id', 'recipient_antenna']]\\\n",
    "    .rename({'recipient_id':'name', 'recipient_antenna':'antenna_id'}, axis=1)\\\n",
    "    .merge(antennas, on='antenna_id', how='left')\n",
    "cdr = pd.concat([outgoing, incoming])\n",
    "cdr['region'] = cdr['region'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25808\n"
     ]
    }
   ],
   "source": [
    "print(len(cdr[cdr['region'] == 'Unknown']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6003.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['Unknown'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique prefectures\n",
    "unique = pd.DataFrame(cdr.groupby('name')['region'].nunique())\n",
    "merged = unique.merge(feats[['name', 'location_count(prefectures)']], on='name')\n",
    "assert (merged['region'].astype('int') == merged['location_count(prefectures)'].astype('int')).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Unknown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9ba6572ff7e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprefecture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefecture\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location_prefectures_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprefecture\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Unknown"
     ]
    }
   ],
   "source": [
    "# Count per prefecture\n",
    "counts = cdr.groupby(['name', 'region'], as_index=False).count()\\\n",
    "    .rename({'antenna_id':'count'}, axis=1)\\\n",
    "    .pivot(index='name', columns='region', values='count').fillna(0)\n",
    "merged = counts.merge(feats, on='name', how='inner')\n",
    "for prefecture in counts.columns:\n",
    "    assert (merged[prefecture].astype('float') == merged['location_prefectures_' + prefecture].astype('float'))\\\n",
    "        .all(), prefecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "AASxnSdfla    29\n",
       "AEKnAnngAv    25\n",
       "AGdRPdgtbK    32\n",
       "AMhiFaRiXH    25\n",
       "ANZEnbkmQy    16\n",
       "              ..\n",
       "zeBKFbSiTi    31\n",
       "zgHOvuGdmZ    23\n",
       "zjKDESgBgP    26\n",
       "zpTweudaaD    27\n",
       "zvoiMpXZyl    25\n",
       "Name: Unknown, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../outputs/featurizer/datasets/countbyregions.csv')\\\n",
    "    .pivot(index='name', columns='regions', values='count')\\\n",
    "    .fillna(0)['Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unknown</th>\n",
       "      <th>location_prefectures_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unknown location_prefectures_Unknown\n",
       "0        5.0                         29.0\n",
       "1        7.0                         25.0\n",
       "2        4.0                         32.0\n",
       "3        7.0                         25.0\n",
       "4        2.0                         16.0\n",
       "..       ...                          ...\n",
       "995      7.0                         31.0\n",
       "996      8.0                         23.0\n",
       "997      6.0                         26.0\n",
       "998      4.0                         27.0\n",
       "999      5.0                         25.0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged['Unknown'] != merged['location_prefectures_Unknown']][['Unknown', 'location_prefectures_Unknown']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>AGOE-NYIVE</th>\n",
       "      <th>AGOU</th>\n",
       "      <th>AKEBOU</th>\n",
       "      <th>AMOU</th>\n",
       "      <th>ANIE</th>\n",
       "      <th>ASSOLI</th>\n",
       "      <th>AVE</th>\n",
       "      <th>BASSAR</th>\n",
       "      <th>BINAH</th>\n",
       "      <th>...</th>\n",
       "      <th>location_prefectures_AGOE-NYIVE_percent</th>\n",
       "      <th>location_prefectures_PLAINE DU MO_percent</th>\n",
       "      <th>location_prefectures_ANIE_percent</th>\n",
       "      <th>location_prefectures_EST-MONO_percent</th>\n",
       "      <th>location_prefectures_Unknown_percent</th>\n",
       "      <th>location_prefectures_KOZAH_percent</th>\n",
       "      <th>location_prefectures_BLITTA_percent</th>\n",
       "      <th>location_count(regions)</th>\n",
       "      <th>location_count(prefectures)</th>\n",
       "      <th>location_count(tower_id)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, AGOE-NYIVE, AGOU, AKEBOU, AMOU, ANIE, ASSOLI, AVE, BASSAR, BINAH, BLITTA, CINKASSE, DANKPEN, DOUFELGOU, EST-MONO, HAHO, KERAN, KOZAH, KPELE, KPENDJAL, KPENDJAL-OUEST, LACS, MOYEN-MONO, OGOU, OTI, OTI-SUD, PLAINE DU MO, SOTOUBOUA, TCHAMBA, TCHAOUDJO, TONE, Unknown, VO, WAWA, ZIO, location_regions_CENTRALE, location_regions_KARA, location_regions_MARITIME, location_regions_PLATEAUX, location_regions_SAVANES, location_regions_Unknown, location_regions_MARITIME_percent, location_regions_KARA_percent, location_regions_CENTRALE_percent, location_regions_PLATEAUX_percent, location_regions_Unknown_percent, location_regions_SAVANES_percent, location_prefectures_AGOE-NYIVE, location_prefectures_AGOU, location_prefectures_AKEBOU, location_prefectures_AMOU, location_prefectures_ANIE, location_prefectures_ASSOLI, location_prefectures_AVE, location_prefectures_BASSAR, location_prefectures_BINAH, location_prefectures_BLITTA, location_prefectures_CINKASSE, location_prefectures_DANKPEN, location_prefectures_DOUFELGOU, location_prefectures_EST-MONO, location_prefectures_HAHO, location_prefectures_KERAN, location_prefectures_KOZAH, location_prefectures_KPELE, location_prefectures_KPENDJAL, location_prefectures_KPENDJAL-OUEST, location_prefectures_LACS, location_prefectures_MOYEN-MONO, location_prefectures_OGOU, location_prefectures_OTI, location_prefectures_OTI-SUD, location_prefectures_PLAINE DU MO, location_prefectures_SOTOUBOUA, location_prefectures_TCHAMBA, location_prefectures_TCHAOUDJO, location_prefectures_TONE, location_prefectures_Unknown, location_prefectures_VO, location_prefectures_WAWA, location_prefectures_ZIO, location_prefectures_BASSAR_percent, location_prefectures_TCHAOUDJO_percent, location_prefectures_VO_percent, location_prefectures_BINAH_percent, location_prefectures_AVE_percent, location_prefectures_TCHAMBA_percent, location_prefectures_ZIO_percent, location_prefectures_TONE_percent, location_prefectures_OGOU_percent, location_prefectures_OTI-SUD_percent, location_prefectures_AMOU_percent, location_prefectures_KPENDJAL_percent, location_prefectures_CINKASSE_percent, location_prefectures_DOUFELGOU_percent, location_prefectures_KERAN_percent, location_prefectures_LACS_percent, location_prefectures_SOTOUBOUA_percent, location_prefectures_WAWA_percent, location_prefectures_KPELE_percent, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 118 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged['AGOE-NYIVE'].astype('float') != merged['location_prefectures_AGOE-NYIVE'].astype('float')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cider2",
   "language": "python",
   "name": "cider"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
