{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.insert(0, '..')\n",
    "from featurizer import *\n",
    "from helpers.utils import *\n",
    "\n",
    "config_file = '../configs/config_new.yml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load directly from pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CDR...\n",
      "Loading recharges...\n",
      "Loading mobile data...\n",
      "Loading mobile data...\n",
      "Loading antennas...\n",
      "Warning: 10 antennas missing location\n"
     ]
    }
   ],
   "source": [
    "datastore = DataStore(cfg_dir=config_file)\n",
    "featurizer = Featurizer(datastore=datastore, clean_folders=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dir('outputs/featurizer')\n",
    "\n",
    "featurizer = Featurizer(config)\n",
    "\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "recharges = pd.read_csv('../synthetic_data/recharges.csv')\n",
    "\n",
    "assert featurizer.cdr.count() == len(cdr)\n",
    "\n",
    "featurizer.cdr = featurizer.cdr.union(featurizer.cdr)\n",
    "featurizer.recharges = featurizer.recharges.union(featurizer.recharges)\n",
    "assert featurizer.cdr.count() == 2*len(cdr)\n",
    "assert featurizer.recharges.count() == 2*len(recharges)\n",
    "\n",
    "featurizer.deduplicate()\n",
    "assert featurizer.cdr.count() == len(cdr)\n",
    "assert featurizer.recharges.count() == len(recharges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer(config)\n",
    "\n",
    "for df in [featurizer.cdr, featurizer.recharges, featurizer.mobiledata, featurizer.mobilemoney]:\n",
    "    assert df.agg({'day':'min'}).collect()[0][0] == pd.to_datetime('2020-01-01')\n",
    "    assert df.agg({'day':'max'}).collect()[0][0] == pd.to_datetime('2020-02-29')\n",
    "\n",
    "featurizer.filter_dates('2020-01-05', '2020-02-01')\n",
    "for df in [featurizer.cdr, featurizer.recharges, featurizer.mobiledata, featurizer.mobilemoney]:\n",
    "    assert df.agg({'day':'min'}).collect()[0][0] == pd.to_datetime('2020-01-05')\n",
    "    assert df.agg({'day':'max'}).collect()[0][0] == pd.to_datetime('2020-02-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Spammers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for number of spammers identified\n",
    "\n",
    "for spammer_threshold in [0, 1.5, 2]:\n",
    "    \n",
    "    featurizer = Featurizer(config)\n",
    "\n",
    "    spammers = len(featurizer.remove_spammers(spammer_threshold=spammer_threshold))\n",
    "    \n",
    "    cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "    cdr['timestamp'] = pd.to_datetime(cdr['timestamp'])\n",
    "    cdr['day'] = cdr['timestamp'].dt.date\n",
    "    grouped = cdr.groupby(['caller_id', 'txn_type']).agg({'day':['count', 'nunique']}).reset_index()\n",
    "    assert len(grouped[grouped['day']['count'] > spammer_threshold*grouped['day']['nunique']]['caller_id'].unique()) == spammers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for removal of spammers\n",
    "\n",
    "spammer_threshold = 1\n",
    "\n",
    "featurizer = Featurizer(config)\n",
    "\n",
    "spammers = featurizer.remove_spammers(spammer_threshold=spammer_threshold)\n",
    "\n",
    "for df in [featurizer.cdr, featurizer.recharges, featurizer.mobiledata, featurizer.mobilemoney]:\n",
    "    \n",
    "    caller_ids = [item[0] for item in featurizer.cdr.select('caller_id').collect()]\n",
    "    assert set(spammers).intersection(set(caller_ids)) == set()\n",
    "    \n",
    "    if 'recipient_id' in df.columns:\n",
    "        recipient_ids = [item[0] for item in featurizer.cdr.select('caller_id').collect()]\n",
    "        assert set(spammers).intersection(set(recipient_ids)) == set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Outlier Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for number of days identified\n",
    "\n",
    "for num_sds in [1, 1.5, 2]:\n",
    "    featurizer = Featurizer(config)\n",
    "\n",
    "    outliers = [pd.to_datetime(item).tz_localize(None) for item in featurizer.filter_outlier_days(num_sds)]\n",
    "\n",
    "    cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "    cdr['timestamp'] = pd.to_datetime(cdr['timestamp'])\n",
    "    cdr['day'] = cdr['timestamp'].dt.floor('d')\n",
    "    grouped = cdr.groupby('day', as_index=False).agg('count')\n",
    "    u = grouped['txn_type'].mean() + num_sds*grouped['txn_type'].std()\n",
    "    l = grouped['txn_type'].mean() - num_sds*grouped['txn_type'].std()\n",
    "    outliers_manual = grouped[(grouped['txn_type'] < l) | (grouped['txn_type'] > u)]['day'].astype('object')\n",
    "    assert list(outliers_manual.unique()) == outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for removal of days\n",
    "\n",
    "num_sds = 2\n",
    "\n",
    "featurizer = Featurizer(config)\n",
    "\n",
    "original_counts = []\n",
    "for df in [featurizer.cdr, featurizer.recharges, featurizer.mobiledata, featurizer.mobilemoney]:\n",
    "    original_counts.append(df.select('day').distinct().count())\n",
    "    \n",
    "num_outliers = len(featurizer.filter_outlier_days(num_sds))\n",
    "\n",
    "for d, df in enumerate([featurizer.cdr, featurizer.recharges, featurizer.mobiledata, featurizer.mobilemoney]):\n",
    "    assert(df.select('day').distinct().count() == original_counts[d] - num_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer(config)\n",
    "\n",
    "statistics = featurizer.diagnostic_statistics('test_output')\n",
    "\n",
    "for fname, name in [('cdr', 'CDR')]:\n",
    "    \n",
    "    df = pd.read_csv('../synthetic_data/' + fname + '.csv')\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    assert((df['timestamp'].max() - df['timestamp'].min()).days + 1 == statistics[name]['Days'])\n",
    "    assert(len(df) == statistics[name]['Transactions'])\n",
    "    assert(len(df['caller_id'].unique()) == statistics[name]['Subscribers'])\n",
    "    if 'recipient_id' in df.columns:\n",
    "        assert(len(df['recipient_id'].unique()) == statistics[name]['Recipients'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer(config)\n",
    "\n",
    "featurizer.diagnostic_plots('test_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDR Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer(config)\n",
    "featurizer.location_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer(config)\n",
    "featurizer.cdr_features()\n",
    "featurizer.international_features()\n",
    "featurizer.location_features()\n",
    "featurizer.recharges_features()\n",
    "featurizer.mobiledata_features()\n",
    "featurizer.mobilemoney_features()\n",
    "featurizer.all_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of records\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "outgoing = cdr.groupby('caller_id').agg('count')\\\n",
    "    [['txn_type']]\n",
    "incoming = cdr.groupby('recipient_id').agg('count')\\\n",
    "    [['txn_type']]\n",
    "txns = pd.concat([outgoing, incoming])\n",
    "txns['caller_id'] = txns.index\n",
    "txn_count = txns.groupby('caller_id').agg('sum')\n",
    "txn_count['name'] = txn_count.index\n",
    "feats = featurizer.features['cdr'].toPandas()\\\n",
    "    [['name', 'cdr_reporting__number_of_records']]\n",
    "feats['cdr_reporting__number_of_records'] = feats['cdr_reporting__number_of_records']\\\n",
    "    .astype('float')\n",
    "merged = txn_count.merge(feats, on='name', how='outer')\n",
    "assert len(merged[merged['txn_type'] != merged['cdr_reporting__number_of_records']]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean call time\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "txns = pd.concat([cdr[['caller_id', 'duration']].rename({'caller_id':'name'}, axis=1), \n",
    "            cdr[['recipient_id', 'duration']].rename({'recipient_id':'name'}, axis=1)])\n",
    "txns = txns.groupby('name', as_index=False).agg('mean')\n",
    "feats = featurizer.features['cdr'].toPandas()\n",
    "feats['cdr_call_duration__allweek__allday__call__mean'] = \\\n",
    "    feats['cdr_call_duration__allweek__allday__call__mean'].astype('float')\n",
    "merged = feats[['name', 'cdr_call_duration__allweek__allday__call__mean']]\\\n",
    "    .merge(txns, on='name')\n",
    "assert len(merged[merged['duration'].astype('int') != \\\n",
    "       merged['cdr_call_duration__allweek__allday__call__mean'].astype('int')]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of contacts\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "txns = cdr[cdr['txn_type'] == 'call']\n",
    "txns = pd.concat([txns[['caller_id', 'recipient_id', 'duration']]\\\n",
    "                      .rename({'caller_id':'name', 'recipient_id':'contact'}, axis=1), \n",
    "                  txns[['caller_id','recipient_id', 'duration']]\\\n",
    "                      .rename({'recipient_id':'name', 'caller_id':'contact'}, axis=1)])\n",
    "contacts = pd.DataFrame(txns.groupby('name')['contact'].nunique())\n",
    "feats = featurizer.features['cdr'].toPandas()\\\n",
    "    [['name', 'cdr_number_of_contacts__allweek__allday__call']]\n",
    "feats['cdr_number_of_contacts__allweek__allday__call'] = \\\n",
    "    feats['cdr_number_of_contacts__allweek__allday__call'].astype('int')\n",
    "merged = feats.merge(contacts, on='name', how='outer')\n",
    "assert len(merged[merged['contact'] != \\\n",
    "                  merged['cdr_number_of_contacts__allweek__allday__call']]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### International Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of outgoing transactions\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "cdr = cdr[cdr['international'] == 'international']\n",
    "feats = featurizer.features['international'].toPandas()\n",
    "inter = cdr.groupby('caller_id', as_index=False).agg('count')[['caller_id', 'txn_type']]\\\n",
    "    .rename({'caller_id':'name'}, axis=1)\n",
    "merged = feats.merge(inter, on='name')\n",
    "assert list(merged['international_all__recipient_id__count'].astype('int')) == \\\n",
    "    list(merged['txn_type'].astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total call duration\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "cdr = cdr[cdr['international'] == 'international']\n",
    "feats = featurizer.features['international'].toPandas()\n",
    "inter = cdr.groupby('caller_id', as_index=False).agg('sum')[['caller_id', 'duration']]\\\n",
    "    .rename({'caller_id':'name'}, axis=1)\n",
    "merged = feats.merge(inter, on='name')\n",
    "assert list(merged['international_call__duration__sum'].fillna(0).astype('float')) == \\\n",
    "    list(merged['duration'].astype('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobile Data Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique days\n",
    "feats = featurizer.features['mobiledata'].toPandas()\n",
    "data = pd.read_csv('../synthetic_data/mobiledata.csv')\n",
    "data['day'] = data['timestamp'].apply(lambda x: x[:10])\n",
    "days = pd.DataFrame(data.groupby('caller_id')['day'].nunique())\n",
    "days['name'] = days.index\n",
    "merged = days.merge(feats, on='name')\n",
    "assert len(merged[merged['day'] != merged['mobiledata_num_days']]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max volume\n",
    "feats = featurizer.features['mobiledata'].toPandas()\n",
    "data = pd.read_csv('../synthetic_data/mobiledata.csv')\n",
    "data = data.groupby('caller_id', as_index=False).agg('max')\\\n",
    "    .rename({'caller_id':'name'}, axis=1)\n",
    "merged = data.merge(feats, on='name')\n",
    "assert list(merged['volume'].astype('int')) == \\\n",
    "    list(merged['mobiledata_max_volume'].astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobile Money Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum outgoing p2p volume\n",
    "feats = featurizer.features['mobilemoney'].toPandas()\n",
    "mm = pd.read_csv('../synthetic_data/mobilemoney.csv')\n",
    "mm = mm[mm['txn_type'] == 'p2p']\n",
    "mm = mm.groupby('caller_id', as_index=False).agg('min')\\\n",
    "    .rename({'caller_id':'name'}, axis=1)\n",
    "merged = mm.merge(feats, on='name', how='outer').fillna(0)\n",
    "assert (merged['mobilemoney_outgoing_p2p_amount_min'].astype('float').round(1) == \\\n",
    "    merged['amount'].astype('float').round(1)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum outgoing p2p volume\n",
    "feats = featurizer.features['mobilemoney'].toPandas()\n",
    "mm = pd.read_csv('../synthetic_data/mobilemoney.csv')\n",
    "outgoing = mm[['caller_id', 'sender_balance_before']]\\\n",
    "    .rename({'caller_id':'name', 'sender_balance_before':'balance'}, axis=1)\n",
    "incoming = mm[['recipient_id', 'recipient_balance_before']]\\\n",
    "    .rename({'recipient_id':'name', 'recipient_balance_before':'balance'}, axis=1)\n",
    "mm = pd.concat([outgoing, incoming])\n",
    "mm = mm.groupby('name', as_index=False).agg('mean')\n",
    "merged = mm.merge(feats, on='name', how='outer').fillna(0)\n",
    "assert (merged['mobilemoney_all_all_balance_before_mean'].astype('float').round(1) == \\\n",
    "    merged['balance'].astype('float').round(1)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recharges Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total recharge\n",
    "feats = featurizer.features['recharges'].toPandas()\n",
    "recharges = pd.read_csv('../synthetic_data/recharges.csv')\\\n",
    "    .rename({'caller_id':'name'}, axis=1)\n",
    "recharges = recharges.groupby('name', as_index=False).agg('sum')\n",
    "merged = recharges.merge(feats, on='name')\n",
    "assert (merged['amount'].astype('float') == merged['recharges_sum'].astype('float')).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = featurizer.features['location'].toPandas()\n",
    "cdr = pd.read_csv('../synthetic_data/cdr.csv')\n",
    "antennas = pd.read_csv('../synthetic_data/antennas.csv')\n",
    "antennas = gpd.GeoDataFrame(antennas, geometry=gpd.points_from_xy(antennas['longitude'], antennas['latitude']))\n",
    "antennas.crs = {\"init\":\"epsg:4326\"}\n",
    "prefectures = gpd.read_file('../synthetic_data/prefectures.geojson')\n",
    "antennas = gpd.sjoin(antennas, prefectures, op='within', how='left')[['antenna_id', 'region']]\n",
    "antennas['region'] = antennas['region'].fillna('Unknown')\n",
    "outgoing = cdr[['caller_id', 'caller_antenna']]\\\n",
    "    .rename({'caller_id':'name', 'caller_antenna':'antenna_id'}, axis=1)\\\n",
    "    .merge(antennas, on='antenna_id', how='left')\n",
    "incoming = cdr[['recipient_id', 'recipient_antenna']]\\\n",
    "    .rename({'recipient_id':'name', 'recipient_antenna':'antenna_id'}, axis=1)\\\n",
    "    .merge(antennas, on='antenna_id', how='left')\n",
    "cdr = pd.concat([outgoing, incoming])\n",
    "cdr['region'] = cdr['region'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique prefectures\n",
    "unique = pd.DataFrame(cdr.groupby('name')['region'].nunique())\n",
    "merged = unique.merge(feats[['name', 'location_count(prefectures)']], on='name')\n",
    "assert (merged['region'].astype('int') == merged['location_count(prefectures)'].astype('int')).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count per prefecture\n",
    "cdr['call'] = 1\n",
    "counts = cdr.groupby(['name', 'region'], as_index=False).count()\\\n",
    "    .rename({'call':'count'}, axis=1)\\\n",
    "    .pivot(index='name', columns='region', values='count').fillna(0)\n",
    "merged = counts.merge(feats, on='name', how='inner')\n",
    "for prefecture in counts.columns:\n",
    "    assert (merged[prefecture].astype('float') == merged['location_prefectures_' + prefecture].astype('float'))\\\n",
    "        .all(), prefecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cider",
   "language": "python",
   "name": "cider"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
